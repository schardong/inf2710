"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"2JR39RH2","journalArticle","2014","Tu, E.; Cao, L.; Yang, J.; Kasabov, N.","A novel graph-based k-means for nonlinear manifold clustering and representative selection","Neurocomputing","","0925-2312","10.1016/j.neucom.2014.05.067","","Many real-world applications expose the nonlinear manifold structure of the lower dimension rather than its high-dimensional input space. This greatly challenges most existing clustering and representative selection algorithms which do not take the manifold characteristics into consideration. The performance of the corresponding learning algorithms can be greatly improved if the manifold structure is considered. In this paper, we propose a graph-based k-means algorithm, GKM, which bears the simplicity of classic k-means while incorporating global information of data geometric distribution. GKM fully exploits the intrinsic manifold structure for appropriate data clustering and representative selection. GKM is evaluated on both synthetic and real-life data sets and achieves very impressive results compared to the state-of-the-art approaches, including classic k-means, kernel k-means, spectral clustering, and clustering through ranking and for representative selection. Given the widespread appearance of manifold structures in real world problems, GKM shows promising potential for partitioning manifold-distributed data. © 2014 Elsevier B.V.","2014","2016-04-04 17:48:05","2016-04-04 17:48:05","","109-122","","","143","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/27D45W9Z/display.html","","","Graph learning; K-means; Manifold clustering; Random walk","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2KV3R4CU","journalArticle","2015","Kasperski, A.; Kurpisz, A.; Zieliński, P.","Approximability of the robust representatives selection problem","Operations Research Letters","","0167-6377","10.1016/j.orl.2014.10.007","","In this paper new complexity and approximation results on the robust versions of the representatives selection problem, under the scenario uncertainty representation, are provided, which extend the results obtained in the recent papers by Dolgui and Kovalev (2012) and Deineko and Woeginger (2013). Namely, it is shown that if the number of scenarios is a part of input, then the min-max (regret) representatives selection problem is not approximable within a ratio of O(log1-εK) for any ε&gt;0, where K is the number of scenarios, unless the problems in NP have quasi-polynomial time algorithms. An approximation algorithm with an approximation ratio of O(logK/loglogK) for the min-max version of the problem is also provided. © 2014 Elsevier B.V. All rights reserved.","2015","2016-04-04 17:48:05","2016-04-04 17:48:05","","16-19","","1","43","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/GQCU7RPE/display.html","","","Computational complexity; Robust optimization; Selection problem; Uncertainty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2S277UP5","manuscript","2015","Bianchi, F.M.; Livi, L.; Rizzi, A.","Two density-based k-means initialization algorithms for non-metric data clustering","","","","","","In this paper, we propose a density-based clusters’ representatives selection algorithm that identifies the most central patterns from the dense regions in the dataset. The method, which has been implemented using two different strategies, is applicable to input spaces with no trivial geometry. Our approach exploits a probability density function built through the Parzen estimator, which relies on a (not necessarily metric) dissimilarity measure. Being a representatives extractor a general-purpose algorithm, our method is obviously applicable in different contexts. However, to test the proposed procedure, we specifically consider the problem of initializing the k-means algorithm. We face problems defined on standard real-valued vectors, labeled graphs, and finally sequences of real-valued vectors and sequences of characters. The obtained results demonstrate the effectiveness of the proposed representative selection method with respect to other state-of-the-art solutions. © 2015 Springer-Verlag London","2015","2016-04-04 17:48:05","2016-04-04 17:48:05","","","","","","","","","","","","","","","English","","Article in Press","Scopus","","Scopus","","DOI: 10.1007/s10044-014-0440-4","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/9Z696VAU/display.html","","","Clustering; Dissimilarity measures; k-means initialization; Non-metric domains; Prototype selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2VUWZRQP","journalArticle","2012","Höche, S.; Krauss, F.; Schonherr, M.; Siegert, F.","A critical appraisal of NLO+PS matching methods","Journal of High Energy Physics","","1126-6708","10.1007/JHEP09(2012)049","","In this publication, uncertainties in and differences between the Mc@Nlo and Powheg methods for matching next-to-leading order QCD calculations with parton showers are discussed. Implementations of both algorithms within the event generator Sherpa and based on Catani-Seymour subtraction are employed to assess the impact on a representative selection of observables. In the case of Mc@Nlo a substantial simplification is achieved by using dipole subtraction terms to generate the first emission. A phase space restriction is employed, which allows to vary in a transparent way the amount of nonsingular radiative corrections that are exponentiated. Effects on various observables are investigated, using the production of a Higgs boson in gluon fusion, with or without an associated jet, as a benchmark process. The case of H+jet production is presented for the first time in an NLO+PS matched simulation. Uncertainties due to scale choices and non-perturbative effects are explored in the production of W ± and Z bosons in association with a jet. Corresponding results are compared to data from the Tevatron and LHC experiments..","2012","2016-04-04 17:48:05","2016-04-04 17:48:05","","","","9","2012","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/ZHASKDKW/display.html","","","QCD phenomenology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"32HJ9H28","journalArticle","2014","Zheng, H.-T.; Gong, S.-Q.; Chen, H.; Jiang, Y.; Xia, S.-T.","Multi-document summarization based on sentence clustering","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","0302-9743","","","A main task of multi-document summarization is sentence selection. However, many of the existing approaches only select top ranked sentences without redundancy detection. In addition, some summarization approaches generate summaries with low redundancy but they are supervised. To address these issues, we propose a novel method named Redundancy Detection-based Multi-document Summarizer (RDMS). The proposed method first generates an informative sentence set, then applies sentence clustering to detect redundancy. After sentence clustering, we conduct cluster ranking, candidate selection, and representative selection to eliminate redundancy. RDMS is an unsupervised multi-document summarization system and the experimental results on DUC 2004 and DUC 2005 datasets indicate that the performance of RDMS is better than unsupervised systems and supervised systems in terms of ROUGE-1, ROUGE-L and ROUGE-SU. © Springer International Publishing Switzerland 2014.","2014","2016-04-04 17:48:05","2016-04-04 17:48:05","","429-436","","","8835","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/5X4UDIXZ/display.html","","","Multi-document summarization; Redundancy detection; Representative selection; Sentence clustering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"34WIT6T3","journalArticle","2013","Suprapto; Wardoyo, R.","Algorithms of the combination of compiler optimization options for automatic performance tuning","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","0302-9743","10.1007/978-3-642-36818-9_10","","It is very natural when people compile their programs, they would require a compiler that gives the best program performance. Even though today's compiler have reached the point in which they provide the users a large number of options, however, because of the unavailability of program input data and insufficient knowledge of the target architecture; it can still seriously limit the accuracy of compile-time performance models. Thus, the problem is how to choose the best combination of optimization options provided by compiler for a given program or program section. This gives rise the requirement of an orchestration algorithm that fast and effective to search for the best optimization combination for a program. There have been several algorithms developed, such as Exhaustive Search (ES); Batch Elimination (BE); Iterative Elimination (IE); Combined Elimination (CE); Optimization Space Exploration (OSE); and Statistical Selection (SS). Based on those of algorithms, in this paper we proposed Heuristics Elimination (HE) algorithm, a simple algorithm that was mostly inspired by OSE with some differences. The HE algorithm uses a heuristic approach by applying genetic algorithm to find the best combination of compiler's optimization options. It is unlike OSE, however, this proposed algorithm starts from a set of some possible combinations randomly selected, then they are iteratively refined by some genetic operators to find one optimal combination (as the solution). © 2013 Springer-Verlag.","2013","2016-04-04 17:51:10","2016-04-04 17:51:10","","91-100","","","7804 LNCS","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/9GR9DDIU/display.html","","","batch elimination; combined elimination; Compiler optimization; exhaustive search; iterative elimination; optimization options; optimization space exploration; orchestration algorithm; performance; statistical selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3AKVMIG9","journalArticle","2004","Lam, R.L.; Welch, W.J.","Comparison of methods based on diversity and similarity for molecule selection and the analysis of drug discovery data.","Methods in molecular biology (Clifton, N.J.)","","1064-3745","","","The concepts of diversity and similarity of molecules are widely used in quantitative methods for designing (selecting) a representative set of molecules and for analyzing the relationship between chemical structure and biological activity. We review methods and algorithms for design of a diverse set of molecules in the chemical space using clustering, cell-based partitioning, or other distance-based approaches. Analogous cell-based and clustering methods are described for analyzing drug-discovery data to predict activity in virtual screening. Some performance comparisons are made. The choice of descriptor variables to characterize chemical structure is also included in the comparative study. We find that the diversity of a selected set is quite sensitive to both the statistical selection method and the choice of molecular descriptors and that, for the dataset used in this study, random selection works surprisingly well in providing a set of data for analysis.","2004","2016-04-04 17:51:10","2016-04-04 17:51:10","","301-316","","","275","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/VN27UHG3/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ISWU2NT","journalArticle","2002","Collins, A.L.; Walling, D.E.","Selecting fingerprint properties for discriminating potential suspended sediment sources in river basins","Journal of Hydrology","","0022-1694","10.1016/S0022-1694(02)00011-2","","The absence of guidelines for pre-selecting the most effective combination of properties for inclusion in a composite fingerprint represents a key methodological uncertainty hampering the wider adoption of the fingerprinting approach for identifying suspended sediment sources. This contribution reports a preliminary attempt to address this issue by testing the discrimination of potential sediment sources within a number of contrasting river basins in the UK and Africa, afforded by a range of sediment properties. Statistical analysis confirms that there is no single diagnostic property capable of discriminating the range of potential suspended sediment sources in the study basins. The use of composite fingerprints based on several constituents drawn from a single group of properties consistently improves sediment source discrimination. However, the level of discrimination afforded by a particular combination of properties is not consistent between the study catchments. Composite fingerprints incorporating constituents selected from several groups of properties using a stepwise statistical selection procedure consistently provide the most robust discrimination of potential sediment sources. Whilst it is not possible to identify a universally applicable optimum composite fingerprint, the results suggest that at present, the most effective means of optimising sediment source discrimination is to identify a number of groups of properties for subsequent use in the establishment of a composite fingerprint. More specifically, this study suggests that measurements of a combination of acid and pyrophosphate-dithionite extractable metals, base cations and organic constituents should provide an effective basis for establishing composite fingerprints for discriminating individual sediment source types. Radiometric properties can also provide useful information for improving sediment source discrimination. The final choice of the groups of properties will necessarily reflect the laboratory facilities available. © 2002 Elsevier Science B.V. All rights reserved.","2002","2016-04-04 17:51:10","2016-04-04 17:51:10","","218-244","","1-4","261","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/2A89EKA6/display.html","","","Composite fingerprints; Fingerprint properties; River basins; Sediment source discrimination; Source fingerprinting; Suspended sediment sources","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"49NI38Z3","journalArticle","2008","Iché-Tarrat, N.; Marsden, C.J.","Examining the performance of DFT methods in uranium chemistry: Does core size matter for a pseudopotential?","Journal of Physical Chemistry A","","1089-5639","10.1021/jp801124u","","We have investigated the performance of DFT in U(VI) chemistry. A large, representative selection of functionals has been tested, in combination with two ECPs developed in Stuttgart that have different-sized cores (60 and 78 electrons for U). In addition, several tests were undertaken with another 14 electron pseudopotential, which was developed in Los Alamos. The experimental database contained vibrational wavenumbers, thermochemical data, and 19F chemical shifts for molecules of the type UF6-nCl n. For the prediction of vibrational wavenumbers, the large-core RECP (14 electrons) gives results that are at least as good as those obtained with the small-core RECP (32 electrons). GGA functionals are as successful as hybrid GGA for vibrational spectroscopy; typical errors are only a few percent with the Stuttgart pseudopotentials. For thermochemistry, hybrid versions of DFT are more successful than GGA, LDA, or meta-GGA. Marginally better results are obtained with a 32 electron ECP than with 14; since the experimental uncertainties are at least 25 kJ/mol for each reaction, the best functionals give results that are essentially indistinguishable from experiment. However, large-basis CCSD(T) results match experiment better than any DFT that we examined. Our findings for NMR spectroscopy are rather disappointing; no combination of pseudopotential, functional, and basis yields even a qualitatively correct prediction of trends in the 19F chemical shifts of UF6-nCln species. Results yielded by the large-core RECP are, in general, slightly less bad than those obtained with the small core. We conclude that DFT cannot be recommended for predictions of NMR spectra in this series of compounds, though this conclusion should not be generalized. Our most important result concerns the good performance of the large-core Stuttgart pseudopotential. Given its computational efficiency, we recommend that it be used with DFT methods for the prediction of molecular geometries, vibrational frequencies, and thermochemistry of a given oxidation state. The hybrid GGA functionals MPW1PW91 and PBEO give the best results overall. © 2008 American Chemical Society.","2008","2016-04-04 17:48:05","2016-04-04 17:48:05","","7632-7642","","33","112","","","Examining the performance of DFT methods in uranium chemistry","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/EXQXF75W/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4A3IZVK8","journalArticle","2008","Song, H.; Feng, H.-Y.","A global clustering approach to point cloud simplification with a specified data reduction ratio","CAD Computer Aided Design","","0010-4485","10.1016/j.cad.2007.10.013","","This paper studies the problem of point cloud simplification by searching for a subset of the original input data set according to a specified data reduction ratio (desired number of points). The unique feature of the proposed approach is that it aims at minimizing the geometric deviation between the input and simplified data sets. The underlying simplification principle is based on clustering of the input data set. The cluster representation essentially partitions the input data set into a fixed number of point clusters and each cluster is represented by a single representative point. The set of the representatives is then considered as the simplified data set and the resulting geometric deviation is evaluated against the input data set on a cluster-by-cluster basis. Due to the fact that the change to a representative selection only affects the configuration of a few neighboring clusters, an efficient scheme is employed to update the overall geometric deviation during the search process. The search involves two interrelated steps. It first focuses on a good layout of the clusters and then on fine tuning the local composition of each cluster. The effectiveness and performance of the proposed approach are validated and illustrated through case studies using synthetic as well as practical data sets. © 2007 Elsevier Ltd. All rights reserved.","2008","2016-04-04 17:48:05","2016-04-04 17:48:05","","281-292","","3","40","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/5EPWVNJE/display.html","","","Clustering; Data reduction; Geometric deviation; Point cloud data; Simplification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4THKQ3IW","conferencePaper","2005","Buchholz, Peter; Thümmler, Axel","Enhancing Evolutionary Algorithms with Statistical Selection Procedures for Simulation Optimization","Proceedings of the 37th Conference on Winter Simulation","978-0-7803-9519-0","","","http://dl.acm.org/citation.cfm?id=1162708.1162855","In this paper, we present an evolution strategy for the optimization of simulation models. Our approach incorporates statistical selection procedures that efficiently select the best individual, where best is defined by the maximum or minimum expected simulation response. We use statistical procedures for the survivor selection during the evolutionary process and for selecting the best individual from a set of candidate best individuals, a so-called elite population, at the end of the evolutionary process. Furthermore, we propose a heuristic selection procedure that reduces a random-size subset, containing the best individual, to at most a predefined size. By means of a stochastic sphere function and a simulation model of a production line, we show that this procedure performs better in terms of number of model evaluations and solution quality than other state-of-the-art statistical selection procedures.","2005","2016-04-05 13:35:55","2016-04-05 15:07:56","2016-04-05 13:35:55","842–852","","","","","","","WSC '05","","","","Winter Simulation Conference","Orlando, Florida","","","","","","ACM Digital Library","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/RFBD5Q3B/Buchholz e Thümmler - 2005 - Enhancing Evolutionary Algorithms with Statistical.pdf; /home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/RGWRCUV2/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5C7DXF63","conferencePaper","2004","Sriver, T.A.; Chrissis, J.W.","A framework for mixed-variable optimization under uncertainty using surrogates and statistical selection","","978-1-56347-716-4","","","","A framework for engineering design optimization is presented that combines generalized pattern search (GPS) with ranking and selection (R&S) and surrogate function approximations. This framework is applied to problems with mixed variables (continuous, discrete numeric, and categorical), that are characterized by inherent variation in system performance. The class of algorithms will be described and illustrated on a small numerical example.","2004","2016-04-04 17:51:10","2016-04-04 17:51:10","","3231-3239","","","5","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/RFG3Q4ZE/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Collection of Technical Papers - 10th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference","","","","","","","","","","","","","","",""
"5SNKSBUN","conferencePaper","2003","Hong, L.J.; Nelson, B.L.","An indifference-zone selection procedure with minimum switching and sequential sampling","","","","","","Statistical ranking and selection (R&S) is a collection of experiment design and analysis techniques for selecting the ""population"" with the largest or smallest mean performance from among a finite set of alternatives. R&S procedures have received considerable research attention in the stochastic simulation community, and they have been incorporated in commercial simulation software. One of the ways that R&S procedures are evaluated and compared is via the expected number of samples (often replications) that must be generated to reach a decision. In this paper we argue that sampling cost alone does not adequately characterize the efficiency of ranking-and-selection procedures, and we introduce a new sequential procedure that provides the same statistical guarantees as existing procedures while reducing the expected total cost of application.","2003","2016-04-04 17:51:10","2016-04-04 17:51:10","","474-480","","","1","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/2BHSKBIT/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Winter Simulation Conference Proceedings","","","","","","","","","","","","","","",""
"67FPZRJE","journalArticle","2007","Kemp, G.J.; Meyerspeer, M.; Moser, E.","Absolute quantification of phosphorus metabolite concentrations in human muscle in vivo by 31P MRS: A quantitative review","NMR in Biomedicine","","0952-3480","10.1002/nbm.1192","","31P MRS offers a unique view of muscle metabolism in vivo, but correct quantification is important. Inter-study correlation of estimates of [Pi] and [phosphocreatine (PCr)] in a number of published studies suggest that the main technical problem in calibrated 31P MRS studies is the measurement of PCr and Pi signal intensities, rather than absolute quantification of [ATP]. For comparison, we discuss the few published biopsy studies of calf muscle and a selection of the many studies of quadriceps muscle. The ATP concentration is close to the value that we obtained in calf muscle in our own study, presented here, on four healthy subjects, by localised 31P MRS using a surface coil incorporating an internal reference and calibrated using an external phantom. However, the freeze-clamp biopsy PCr concentration is ∼20% lower than the value obtained by 31P MRS, consistent with PCr breakdown by creatine kinase during freezing. Finally, we illustrate some consequences of uncertainty in resting [PCr] for analysis of mitochondrial function from PCr kinetics using a published 31P MRS study of exercise and recovery: the lower the assumed resting [PCr], the lower the absolute rate of oxidative ATP synthesis estimated from the PCr resynthesis rate; in addition, the lower the assumed resting [PCr], or the higher the assumed [total, creatine], the higher the apparent resting [ADP], and therefore the more sigmoid the relationship between the rate of oxidative ATP synthesis and [ADP]. Correct quantification of resting metabolite concentrations is crucially important for this sort of analysis. Our own results ([PCr] = 33 ± 2 mM, [Pi] = 4.5 ± 0.2 mM, and [ATP] = 8.2 ± 0.4 mM; mean ± SEM) are close to the overall mean values of the 10 published studies on calf muscle by 'calibrated, 31P MRS (as in the present work), and of [PCr] and [Pi] in a representative selection of 'uncalibrated 31P MRS studies (i.e. from measured PCr/ATP and Pi/ATP ratios, assuming a literature value for [ATP]. Copyright © 2007 John Wiley &amp; Sons, Ltd.","2007","2016-04-04 17:48:05","2016-04-04 17:48:05","","555-565","","6","20","","","Absolute quantification of phosphorus metabolite concentrations in human muscle in vivo by 31P MRS","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/2E566NS7/display.html","","","31P MRS; Absolute quantification; Human calf muscle; Mitochondrial function","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6HVWDW82","conferencePaper","1991","Lenz, Reiner; Osterberg, Mats","Learning filter systems with maximum correlation and maximum separation properties","","978-0-8194-0578-4","","","","A system that can be used as a feature extraction unit in a low-level pattern recognition system is described. It is assumed that such a system acts as a linear mapping between the pattern space and the feature space. It can therefore be completely described by a number of filter kernels. These filter kernels are usually constructed by the designer of the system. In the approach to filter design described in this paper, the filter kernels are not created manually. Instead, the authors feed the system during the training period with a representative selection of the patterns that they want to recognize. During the training phase, a learning rule (based on a quality function) is used to update the current form of the filter functions. After the training period, there is a filter system that is is optimally adapted to the recognition of this particular set of patterns of interest. In the first part of the paper, some results from work on group theoretical filter design as described. Within this framework, optimal filter functions can be constructed for a large class of pattern recognition problems. These analytical solutions can then be compared with the filter functions learned by our system. The overall structure of the system and several variations of the basic model are described. A quality function is introduced, and a learning filter system is described as an optimization process. This leads to update rules that are significantly different from other, similar, systems investigated previously. Finally, the performance of the system with the help of several examples is demonstrated.","1991","2016-04-04 17:48:05","2016-04-04 17:48:05","","784-795","","","1469","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/MC6UPHVD/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of SPIE - The International Society for Optical Engineering","","","","","","","","","","","","","","",""
"7KISGC9F","conferencePaper","2006","Lee, Loo Hay; Chew, Ek Peng; Teng, Suyan","Integration of Statistical Selection with Search Mechanism for Solving Multi-objective Simulation-optimization Problems","Proceedings of the 38th Conference on Winter Simulation","978-1-4244-0501-5","","","http://dl.acm.org/citation.cfm?id=1218112.1218170","In this paper, we consider a multi-objective simulation optimization problem with three features: huge solution space, high uncertainty in performance measures, and multi-objective problem which requires a set of nondominated solutions. Our main purpose is to study how to integrate statistical selection with search mechanism to address the above difficulties, and to present a general solution framework for solving such problems. Here due to the multi-objective nature, statistical selection is done by the multi-objective computing budget allocation (MOCBA) procedure. For illustration, MOCBA is integrated with two meta-heuristics: multi-objective evolutionary algorithm (MOEA) and nested partitions (NP) to identify the nondominated solutions for two inventory management case study problems. Results show that, the integrated solution framework has improved both search efficiency and simulation efficiency. Moreover, it is capable of identifying a set of non-dominated solutions with high confidence.","2006","2016-04-05 13:35:55","2016-04-05 15:08:04","2016-04-05 13:35:55","294–303","","","","","","","WSC '06","","","","Winter Simulation Conference","Monterey, California","","","","","","ACM Digital Library","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/TDD679VT/Lee et al. - 2006 - Integration of Statistical Selection with Search M.pdf; /home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/MRUCUVM9/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7SDS3VQH","journalArticle","2006","Dewar, R.C.; Juretić, D.; Županović, P.","The functional design of the rotary enzyme ATP synthase is consistent with maximum entropy production","Chemical Physics Letters","","0009-2614","10.1016/j.cplett.2006.08.095","","We show that the molecular motor ATP synthase has evolved in accordance with the statistical selection principle of Maximum Shannon Entropy and one of its corollaries, Maximum Entropy Production. These principles predict an optimal angular position for the ATP-binding transition close to the experimental value; an inverse relation between the optimal gearing ratio and the proton motive force (pmf); optimal operation at an inflection point in the curve of ATP synthesis rate versus pmf, enabling rapid metabolic control; and a high optimal free energy conversion efficiency. Our results suggest a statistical interpretation for the evolutionary optimization of ATP synthase function. © 2006 Elsevier B.V. All rights reserved.","2006","2016-04-04 17:51:10","2016-04-04 17:51:10","","177-182","","1-3","430","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/FX8VATBF/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7U8N7QQ6","conferencePaper","2013","Kumar, V.; Hahn, J.; Zoubir, A.M.","Band selection for hyperspectral images based on self-tuning spectral clustering","","978-0-9928626-0-2","","","","Hyperspectral imaging (HSI) is an emerging technique,which allows to consistently capture images in the visible as well as infrared light range. Many materials can be easily discriminated by means of their spectra, rendering HSI an interesting method for the reliable classification of contents in a scene. As the number of features for each pixel in hyperspectral images is considerably high, further processing and classification is time consuming and stresses resources. Thus, efficient methods to select useful bands are required. We present a novel two-step scheme based on a clustering approach followed by representatives selection from each cluster. The classification results of real hyperspectral images demonstrate that the proposed method easily outperforms common as well as state-of-the-art methods. © 2013 EURASIP.","2013","2016-04-04 17:48:05","2016-04-04 17:48:05","","","","","","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/ZP7WS396/display.html","","","band selection; Classification; Hyperspectral imaging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","European Signal Processing Conference","","","","","","","","","","","","","","",""
"93SG4FKQ","journalArticle","2014","Darriba, D.; Taboada, G.L.; Doallo, R.; Posada, D.","High-performance computing selection of models of DNA substitution for multicore clusters","International Journal of High Performance Computing Applications","","1094-3420","10.1177/1094342013495095","","This paper presents the high-performance computing (HPC) support of jModelTest2, the most popular bioinformatic tool for the statistical selection of models of DNA substitution. As this can demand vast computational resources, especially in terms of processing power, jModelTest2 implements three parallel algorithms for model selection: (1) a multithreaded implementation for shared memory architectures; (2) a message-passing implementation for distributed memory architectures, such as clusters; and (3) a hybrid shared/distributed memory implementation for clusters of multicore nodes, combining the workload distribution across cluster nodes with a multithreaded model optimization within each node. The main limitation of the shared and distributed versions is the workload imbalance that generally appears when using more than 32 cores, a direct consequence of the heterogeneity in the computational cost of the evaluated models. The hybrid shared/distributed memory version overcomes this issue reducing the workload imbalance through a thread-based decomposition of the most costly model optimization tasks. The performance evaluation of this HPC application on a 40-core shared memory system and on a 528-core cluster has shown high scalability, with speedups of the multithreaded version of up to 32, and up to 257 for the hybrid shared/distributed memory implementation. This can represent a reduction in the execution time of some analyses from 4 days down to barely 20 minutes. The implementation of the three parallel execution strategies of jModelTest2 presented in this paper are available under a GPL license at http://code.google.com/jmodeltest2. © The Author(s) 2013.","2014","2016-04-04 17:51:10","2016-04-04 17:51:10","","112-125","","1","28","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/C2CV7JUR/display.html","","","High-performance computing (HPC); Message-Passing in Java (MPJ); multicore cluster; nucleotide substitution; Performance evaluation; phylogeny","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"965I29IA","conferencePaper","2014","Tien, S.-L.A.; Taylor, C.; Wanke, C.","Representative weather-impact scenarios for strategic traffic flow planning","","978-1-62410-282-0","","","","This paper proposes a methodology for using ensemble weather forecasts to assist in air traffic flow contingency management. Specifically, the weather ensemble members are converted into scenarios of weather impact, and performance metrics are formulated to assess the similarity of these scenarios. Metrics for measuring weather impacts on both en route sectors and airports are considered in scenario clustering. Representative scenarios are selected using a proposed index, which quantifies the representativity of scenarios and addresses the requirements of representative selections. In a quantitative experiment, historical demand and weather forecast data from a sample weather day are simulated to demonstrate the proposed methodology. When combining en route and terminal impact metrics, a weighting approach between two metric categories is employed to reflect operational preferences since their tradeoff may influence the clustering results as well as the representative selection. Lastly, the strategic flow management plans for a few selected representative scenarios are developed and their performance results are analyzed. It shows that the scenarios in the same cluster have a similar response to the plan that is the most effective on its representative scenario.","2014","2016-04-04 17:48:05","2016-04-04 17:48:05","","","","","","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/5PP9ITDJ/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AIAA AVIATION 2014 -14th AIAA Aviation Technology, Integration, and Operations Conference","","","","","","","","","","","","","","",""
"9J2T5DQT","journalArticle","1993","Gola, M.M.; Soma, A.","Design of a carbon fiber robot: Architectural choices and design balancing","Lecture Notes in Control and Information Sciences","","0170-8643","","","The design of a machine, and therefore also the design of the structure and mechanisms of the high performance robot here described, is obviously a very demanding task in which design expertise, architectural choices and algorithmic optimization analyses are so intertwined that only with difficulty can the designer state it as a logical sequence of decisions. The case under examination proves to be no exception to this; an illustration is attempted here of the process which eventually led to the definitive choices for the robot. In the first part the objectives of the design are stated, and description is made of a representative selection of the different architectures and variants which have been proposed to the desired goal, All the constructional choices have been weighted in the light of different needs, such as cost, mantainability, dynamic performance, production technology, ease of assembly. During this phase, decisions were taken on the bases of qualitative projections or of comparative merits between different solution, with the aid of simple engineering calculations not reported here. Once the final architecture was attained, a general analysis was formulated through a full finite element model; however, a number of critical components had stiffness values which were very difficult to correctly predict. It proved therefore mandatory to employ identification methods, some of them original and specially developed from these authors, making use of experimental data from preliminary prototypes. Brief reference is made to these methods. In the final stage, attention was focused on the relation between stiffness of main bearings and of structural members. It was then possible to clarify the limitations of different choices in terms of static strength and of frequency response, and to balance the design. © 1993, Springer Verlag. All Rights Reserved.","1993","2016-04-04 17:48:05","2016-04-04 17:48:05","","275-284","","","187","","","Design of a carbon fiber robot","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/5ZERSKUS/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9PQ8SA2R","journalArticle","2015","Liebman, E.; Chor, B.; Stone, P.","Representative Selection in Nonmetric Datasets","Applied Artificial Intelligence","","0883-9514","10.1080/08839514.2015.1071092","","This study considers the problem of representative selection: choosing a subset of data points from a dataset that best represents its overall set of elements. This subset needs to inherently reflect the type of information contained in the entire set, while minimizing redundancy. For such purposes, clustering might seem like a natural approach. However, existing clustering methods are not ideally suited for representative selection, especially when dealing with nonmetric data, in which only a pairwise similarity measure exists. In this article we propose δ-medoids, a novel approach that can be viewed as an extension of the k-medoids algorithm and is specifically suited for sample representative selection from nonmetric data. We empirically validate δ-medoids in two domains: music analysis and motion analysis. We also show some theoretical bounds on the performance of δ-medoids and the hardness of representative selection in general. Copyright © 2015 Taylor & Francis Group, LLC.","2015","2016-04-04 17:48:05","2016-04-04 17:48:05","","807-838","","8","29","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/426HJ5VK/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RIKVAHE","journalArticle","2001","Benedict, S.H.; Cardinale, R.M.; Wu, Q.; Zwicker, R.D.; Broaddus, W.C.; Mohan, R.","Intensity-modulated stereotactic radiosurgery using dynamic micro-multileaf collimation","International Journal of Radiation Oncology Biology Physics","","0360-3016","10.1016/S0360-3016(01)01487-0","","Purpose: The implementation of dynamic leaf motion on a micro-multileaf collimator system provides the capability for intensity-modulated stereotactic radiosurgery (IMSRS), and the consequent potential for improved dose distributions for irregularly shaped tumor volumes adjacent to critical organs. This study explores the use of IMSRS to provide improved tumor coverage and normal tissue sparing for small cranial tumors relative to plans based on multiple fixed uniform-intensity beams or traditional circular collimator arc-based stereotactic techniques. Methods and Materials: Four patient cases involving small brain lesions are presented and analyzed. The cases were chosen to include a representative selection of target shapes, number of targets, and adjacent critical areas. Patient plans generated for these comparisons include standard arcs with multiple circular collimators, and fixed noncoplanar static fields with uniform-intensity beams and IMSRS. Parameters used for evaluation of the plans include the percentage of irradiated volume to tumor volume (PITV), normal tissue dose-volume histograms, and dose-homogeneity ratios. All IMSRS plans were computed using previously established IMRT techniques adapted for use with the BrainLAB M3 micro-multileaf collimator. The algorithms comprising the IMRT system for optimization of intensity distributions and conversion into leaf trajectories of the BrainLab M3 were developed at our institution. The ADAC Pinnacle 3 radiation treatment-planning system was used for dose calculations and for input of contours for target volumes and normal critical structures. Results: For all cases, the IMSRS plans showed a high degree of conformity of the dose distribution with the target shape. The IMSRS plans provided either (1) a smaller volume of normal tissue irradiated to significant dose levels, generally taken as doses greater than 50% of the prescription, or (2) a lower dose to an important adjacent critical organ. The reduction in volume of normal tissue irradiated in the IMSRS plans ranged from 10% to 50% relative to the other arc and uniform fixed-field plans. Conclusion: The case studies presented for IMSRS demonstrate significant dosimetric improvements for small, irregularly shaped lesions of the brain when compared to treatments using multiple static fields or standard SRS arc techniques with circular collimators. For all cases, the IMSRS plan yielded a smaller volume of normal tissue irradiated, and/or a reduction in the volume of an adjacent critical organ (i.e., brainstem) irradiated to significant dose levels. Copyright © 2001 Elsevier Science Inc.","2001","2016-04-04 17:48:05","2016-04-04 17:48:05","","751-758","","3","50","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/VZKQABIU/display.html","","","Intensity-modulated radiotherapy; Micro-multileaf collimation; Stereotactic radiosurgery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A9MJMCKM","journalArticle","2006","Vedani, A.; Dobler, M.; Lill, M.A.","The challenge of predicting drug toxicity in silico","Basic and Clinical Pharmacology and Toxicology","","1742-7835","10.1111/j.1742-7843.2006.pto_471.x","","Poor pharmacokinetics, side effects and compound toxicity are frequent causes of late-stage failures in drug development. A safe in silico identification of adverse effects triggered by drugs and chemicals would be highly desirable as it not only bears economical potential but also spawns a variety of ecological benefits: sustainable resource management, reduction of animal models and possibly less risky clinical trials. In computer-aided drug discovery, both existing and hypothetical compounds may be studied; the methods are fast, reproducible, and typically based on human bioregulators, making the question of transferability obsolete. In the recent past, our laboratory contributed towards the development of in silico concepts (→ multi-dimensional QSAR) and validated a series of ""virtual test kits"" based on the oestrogen, androgen, thyroid, and aryl hydrocarbon receptor (endocrine disruption, receptor-mediated toxicity) as well as on the enzyme cytochrome P450 3A4 (metabolic transformations, drug-drug interactions). The test kits are based on the three-dimensional structure of their target protein (i.e. ERαβ, AR, TRαβ, CYP450) or a surrogate thereof (AhR) and were trained using a representative selection of 362 substances. Subsequent evaluation of 107 compounds different therefrom showed that binding affinities are predicted close to experimental uncertainty. These results suggest that our approach is suited for the in silico identification of adverse effects triggered by drugs and chemicals and encouraged us to compile an Internet Database for the virtual screening of drugs and chemicals for toxic effects. © Basic &amp; Clinical Pharmacology &amp; Toxicology 2006.","2006","2016-04-04 17:48:05","2016-04-04 17:48:05","","195-208","","3","99","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/93XIBK4E/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AA4NZDVU","journalArticle","2011","Chu, W.-T.; Li, C.-J.; Tseng, S.-C.","Travelmedia: An intelligent management system for media captured in travel","Journal of Visual Communication and Image Representation","","1047-3203","10.1016/j.jvcir.2010.10.008","","A media management system exploiting characteristics of travel media is designed to facilitate efficient management and browsing. According to travel schedules, travel media often have implicit thematic structure. Correlation between different modalities also provides implicit cues to media analysis. In this system, we exploit techniques of near-duplicate detection to select representative photos, and determine region-of-interest in photos to enhance browsing experience. For face-name association, a face clustering module based on visual language models is constructed. To systematically segment travel videos of bad visual quality and significant motion, we explore correlation between photos and videos based on approximate visual word histogram matching. Experimental results demonstrate the effectiveness of the proposed approaches and show that they are practical functions. © 2010 Elsevier Inc. All rights reserved.","2011","2016-04-04 17:48:05","2016-04-04 17:48:05","","93-104","","1","22","","","Travelmedia","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/25MGGEXQ/display.html","","","Face clustering; Photo browsing; Region of interest; Representative selection; Travel media management; Vector space model; Video scene detection; Visual words","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AAJXI3VD","conferencePaper","2014","Jindaluang, W.; Chouvatut, V.; Kantabutra, S.","Under-sampling by algorithm with performance guaranteed for class-imbalance problem","","978-1-4799-4963-2","","10.1109/ICSEC.2014.6978197","","Class-imbalance problem is the problem that the number, or data, in the majority class is much more than in the minority class. Traditional classifiers cannot sort out this problem because they focus on the data in the majority class than on the data in the minority class, and then they predict some upcoming data as the data in the majority class. Under-sampling is an efficient way to handle this problem because this method selects the representatives of the data in the majority class. For this reason, under-sampling occupies shorter training period than over-sampling. The only problem with the under-sampling method is that a representative selection, in all probability, throws away important information in a majority class. To overcome this problem, we propose a cluster-based under-sampling method. We use a clustering algorithm that is performance guaranteed, named k-centers algorithm, which clusters the data in the majority class and selects a number of representative data in many proportions, and then combines them with all the data in the minority class as a training set. In this paper, we compare our approach with k-means on five datasets from UCI with two classifiers: 5-nearest neighbors and c4.5 decision tree. The performance is measured by Precision, Recall, F-measure, and Accuracy. The experimental results show that our approach has higher measurements than the k-means approach, except Precision where both the approaches have the same rate. © 2014 IEEE.","2014","2016-04-04 17:48:05","2016-04-04 17:48:05","","215-221","","","","","","","","","","","","","English","","","Scopus","","Scopus","","DOI: 10.1109/ICSEC.2014.6978197","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/IISZIPUU/display.html","","","Classification; Class-imbalance problem; K-centers algorithm; Under-sampling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2014 International Computer Science and Engineering Conference, ICSEC 2014","","","","","","","","","","","","","","",""
"B4EPRT8U","conferencePaper","2008","Arslan, U.; McCartney, M.P.; Bhargava, M.; Li, X.; Mai, K.; Pileggi, L.T.","Variation-tolerant SRAM sense-amplifier timing using configurable replica bitlines","","","","10.1109/CICC.2008.4672108","","A configurable replica bitline (cRBL) technique for controlling sense-amplifier enable (SAE) timing for small-swing bitline SRAMs is described. Post-silicon selection of a subset of replica bitline driver cells from a statistically designed pool of cells facilitates precise SAE timing. An exponential reduction in timing variation is enabled by statistical selection of driver cells, which can provide 14x reduction in SAE timing uncertainty with 200x less area and power than a conventional RBL with equivalent variation control. We describe the post-silicon test and configuration methodology necessary for cRBLs. To demonstrate the efficacy of the proposed cRBL technique, we present measured results from a 90nm bulk CMOS 64kb SRAM testchip. ©2008 IEEE.","2008","2016-04-04 17:51:10","2016-04-04 17:51:10","","415-418","","","","","","","","","","","","","English","","","Scopus","","Scopus","","DOI: 10.1109/CICC.2008.4672108","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/JEGENTJR/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Custom Integrated Circuits Conference","","","","","","","","","","","","","","",""
"BBFA4IMX","conferencePaper","2004","Pinkers, R.P.J.; Knijnenburg, P.M.W.; Haneda, M.; Wijshoff, H.A.G.","Statistical selection of compiler options","","978-0-7695-2251-7","","10.1109/MASCOT.2004.1348305","","Compilers have many switches or options that enable certain code optimizations. However, it is well known that the optimal set of options to be turned on is dependent on both the application as well as the target architecture. In many cases, standard settings like -O3 produce suboptimal results due to negative interference of some of the options they contain. In this paper, we propose an automatic iterative procedure to turn on or to turn off compiler options. This procedure is based on Orthogonal Arrays that are used for a statistical analysis of profile information to calculate the main effect of the options. We show that our approach outperforms -O3 of GCC on six SPEC benchmarks. © 2004 IEEE.","2004","2016-04-04 17:51:10","2016-04-04 17:51:10","","494-501","","","","","","","","","","","","","English","","","Scopus","","Scopus","","DOI: 10.1109/MASCOT.2004.1348305","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/TV9M76JR/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Computer Society's Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems, MASCOTS","","","","","","","","","","","","","","",""
"BNSZ383X","conferencePaper","2011","Witheephanich, K.; De, La Peña; Hayes, M.J.","Min-max model predictive power control strategy for CDMA cellular networks","","978-3-902661-93-7","","10.3182/20110828-6-IT-1002.02134","","This paper applies an open-loop min-max MPC strategy to the uplink radio power control problem for a CDMA cellular network assessed over time-varying channels. The new power control algorithm is shown to robustly compensate for channel fading uncertainty as well as to reduce the effect of interference. This is achieved by implementing a computationally efficient min-max MPC mechanism based on a simple model of the tracking error that is estimated at each sampling time from the local SINR. The numerical efficiency of the resulting design is benchmarked against a number of existing strategies via a representative selection of simulation scenarios. © 2011 IFAC.","2011","2016-04-04 17:48:05","2016-04-04 17:48:05","","5657-5662","","","18","","","","","","","","","","English","","","Scopus","","Scopus","","DOI: 10.3182/20110828-6-IT-1002.02134","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/6QMU3Q9I/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IFAC Proceedings Volumes (IFAC-PapersOnline)","","","","","","","","","","","","","","",""
"BU69X3Q8","conferencePaper","2015","Ouyang, C.-S.","Feature selection with a supervised similarity-based k-medoids clustering","","978-1-4799-4216-9","","10.1109/ICMLC.2014.7009669","","A supervised similarity-based k-medoids (SSKM) clustering algorithm is proposed for feature selection in classification problems. The set of original features is iteratively partitioned into k clusters, each of which is composed of similar features and represented by a feature yielding the maximum total of similarities with the other features in the duster. A supervised similarity measure is introduced to evaluate the similarity between two features for incorporating information of class labels of training patterns during clustering and representative selection. Experimental results show that our proposed method can select a more effective set of features for classification problems. © 2014 IEEE.","2015","2016-04-04 17:48:05","2016-04-04 17:48:05","","562-566","","","2","","","","","","","","","","English","","","Scopus","","Scopus","","DOI: 10.1109/ICMLC.2014.7009669","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/9DMNAK29/display.html","","","Classification; Dimension reduction; Feature selection; K-medoids; Mutual information; Supervised similarity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Machine Learning and Cybernetics","","","","","","","","","","","","","","",""
"BWTQCR6Q","journalArticle","2009","Chatziioannou, A.; Moulos, P.; Kolisis, F.N.","Gene ARMADA: An integrated multi-analysis platform for microarray data implemented in MATLAB","BMC Bioinformatics","","1471-2105","10.1186/1471-2105-10-354","","Background: The microarray data analysis realm is ever growing through the development of various tools, open source and commercial. However there is absence of predefined rational algorithmic analysis workflows or batch standardized processing to incorporate all steps, from raw data import up to the derivation of significantly differentially expressed gene lists. This absence obfuscates the analytical procedure and obstructs the massive comparative processing of genomic microarray datasets. Moreover, the solutions provided, heavily depend on the programming skills of the user, whereas in the case of GUI embedded solutions, they do not provide direct support of various raw image analysis formats or a versatile and simultaneously flexible combination of signal processing methods. Results: We describe here Gene ARMADA (Automated Robust MicroArray Data Analysis), a MATLAB implemented platform with a Graphical User Interface. This suite integrates all steps of microarray data analysis including automated data import, noise correction and filtering, normalization, statistical selection of differentially expressed genes, clustering, classification and annotation. In its current version, Gene ARMADA fully supports 2 coloured cDNA and Affymetrix oligonucleotide arrays, plus custom arrays for which experimental details are given in tabular form (Excel spreadsheet, comma separated values, tab-delimited text formats). It also supports the analysis of already processed results through its versatile import editor. Besides being fully automated, Gene ARMADA incorporates numerous functionalities of the Statistics and Bioinformatics Toolboxes of MATLAB. In addition, it provides numerous visualization and exploration tools plus customizable export data formats for seamless integration by other analysis tools or MATLAB, for further processing. Gene ARMADA requires MATLAB 7.4 (R2007a) or higher and is also distributed as a stand-alone application with MATLAB Component Runtime. Conclusion: Gene ARMADA provides a highly adaptable, integrative, yet flexible tool which can be used for automated quality control, analysis, annotation and visualization of microarray data, constituting a starting point for further data interpretation and integration with numerous other tools. © 2009 Chatziioannou et al; licensee BioMed Central Ltd.","2009","2016-04-04 17:51:10","2016-04-04 17:51:10","","354","","","10","","","Gene ARMADA","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/KPP9JB8G/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C9IRSANU","journalArticle","2013","Deineko, V.G.; Woeginger, G.J.","Complexity and in-approximability of a selection problem in robust optimization","4OR","","1619-4500","10.1007/s10288-012-0227-7","","We establish strong NP-hardness and in-approximability of the so-called representatives selection problem, a tool selection problem in the area of robust optimization. Our results answer a recent question of Dolgui and Kovalev (4OR Q J Oper Res 10:181-192, 2012). © 2013 Springer-Verlag Berlin Heidelberg.","2013","2016-04-04 17:48:05","2016-04-04 17:48:05","","249-252","","3","11","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/A82VMADE/display.html","","","Combinatorial optimization; Computational complexity; Robust optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CQXZHTD7","journalArticle","2012","Almomani, M.H.; Rahman, R.A.","Selecting the best system using the three stage and the four-stage selection approaches","Applied Mathematical Sciences","","1312-885X","","","Statistical selection approaches are used to select the best stochastic system from a Finite set of alternatives. The best system will be the system with minimum or maximum performance measure. We consider the problem of selecting the best system when the number of alternative systems is huge. Three-Stage and Four-Stage selection approaches are proposed to solve this problem. The main strategy in these two selection approaches involves a combination method of cardinal and or-dinal optimization. Ordinal optimization procedure is used to reduce the number of systems in the search space such that to be appropriate for cardinal optimization procedures. Three-Stage selection approach consists three procedures; Ordinal Optimization, Subset Selection and Indifference-Zone. While, Four-Stage selection approach consists four procedures; Ordinal Optimization, Optimal Computing Budget Allocation, Subset Selection and Indifference-Zone. In this paper, we compare the performance between the two selection approaches; the Three-Stage and Four-Stage approaches. The numerical results show that the per-formance of Four-Stage selection approach is better compare to Three-Stage selection approach in different aspects.","2012","2016-04-04 17:51:10","2016-04-04 17:51:10","","1955-1972","","37-40","6","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/ZQD2386E/display.html","","","Indifference-zone; Optimal computing budget allocation; Ordinal optimization; Ranking and selection; Simulation optimization; Subset selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DI899N33","journalArticle","1998","Ikonomopoulos, A.; Endou, A.","Wavelet decomposition and radial basis function networks for system monitoring","IEEE Transactions on Nuclear Science","","0018-9499","10.1109/23.725267","","Two approaches are coupled to develop a novel collection of black box models for monitoring operational parameters in a complex system. The idea springs from the intention of obtaining multiple predictions for each system variable and fusing them before they are used to validate the actual measurement. The proposed architecture pairs the analytical abilities of the discrete wavelet decomposition with the computational power of radial basis function networks. Members of a wavelet family are constructed in a systematic way and chosen through a statistical selection criterion that optimizes the structure of the network. Network parameters are further optimized through a quasi-Newton algorithm. The methodology is demonstrated utilizing data obtained during two transients of the Monju fast breeder reactor. The models developed are benchmarked with respect to similar regressors based on Gaussian basis functions. © 1998 IEEE.","1998","2016-04-04 17:51:10","2016-04-04 17:51:10","","2293-2301","","5","45","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/2MS38FWF/display.html","","","Fast breeder reactors; Radial basis function networks; Statistical selection criteria; System monitoring; Wavelet-adapted neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E33JIW26","journalArticle","2001","Richardson, D.S.","Measures of skill and value of ensemble prediction systems, their interrelationship and the effect of ensemble size","Quarterly Journal of the Royal Meteorological Society","","0035-9009","10.1256/smsqj.57714","","Ensemble forecasts provide probabilistic predictions for the future state of the atmosphere. Usually the probability of a given event E is determined from the fraction of ensemble members which predict the event. Hence there is a degree of sampling error inherent in the predictions. In this paper a theoretical study is made of the effect of ensemble size on forecast performance as measured by a reliability diagram and Brier (skill) score, and on users by using a simple cost-loss decision model. The relationship between skill and value, and a generalized skill score, dependent on the distribution of users, are discussed. The Brier skill score is reduced from its potential level for all finite-sized ensembles. The impact is most significant for small ensembles, especially when the variance of forecast probabilities is also small. The Brier score for a set of deterministic forecasts is a measure of potential predictability, assuming the forecasts are representative selections from a reliable ensemble prediction system (EPS). There is a consistent effect of finite ensemble size on the reliability diagram. Even if the underlying distribution is perfectly reliable, sampling this using only a small number of ensemble members introduces considerable unreliability. There is a consistent over-forecasting which appears as a clockwise tilt of the reliability diagram. It is important to be aware of the expected effect of ensemble size to avoid misinterpreting results. An ensemble of ten or so members should not be expected to provide reliable probability forecasts. Equally, when comparing the performance of different ensemble systems, any difference in ensemble size should be considered before attributing performance differences to other differences between the systems. The usefulness of an EPS to individual users cannot be deduced from the Brier skill score (nor even directly from the reliability diagram). An EPS with minimal Brier skill may nevertheless be of substantial value to some users, while small differences in skill may hide substantial variation in value. Using a simple cost-loss decision model, the sensitivity of users to differences in ensemble size is shown to depend on the predictability and frequency of the event and on the cost-loss ratio of the user. For an extreme event with low predictability, users with low cost-loss ratio will gain significant benefits from increasing ensemble size from 50 to 100 members, with potential for substantial additional value from further increases in number of members. This sensitivity to large ensemble size is not evident in the Brier skill score. A generalized skill score, dependent on the distribution of users, allows a summary performance measure to be tuned to a particular aspects of EPS performance.","2001","2016-04-04 17:48:05","2016-04-04 17:48:05","","2473-2489","","577","127","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/72NZC7XG/display.html","","","Brier score; Reliability diagram","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EN7738FS","journalArticle","2011","Hahn, S.; Voccio, J.; Bermond, S.; Park, D.-K.; Bascuñán, J.; Kim, S.-B.; Masaru, T.; Iwasa, Y.","Field performance of an optimized stack of YBCO square ""annuli"" for a compact NMR magnet","IEEE Transactions on Applied Superconductivity","","1051-8223","10.1109/TASC.2010.2103920","","The spatial field homogeneity and time stability of a trapped field generated by a stack of YBCO square plates with a center hole (square ""annuli"") was investigated. By optimizing stacking of magnetized square annuli, we aim to construct a compact NMR magnet. The stacked magnet consists of 750 thin YBCO plates, each 40-mm square and 80-μm thick with a 25-mm bore, and has a Ø10 mm room-temperature access for NMR measurement. To improve spatial field homogeneity of the 750-plate stack (YP750) a three-step optimization was performed: 1) statistical selection of best plates from supply plates; 2) field homogeneity measurement of multi-plate modules; and 3) optimal assembly of the modules to maximize field homogeneity. In this paper, we present analytical and experimental results of field homogeneity and temporal stability at 77 K, performed on YP750 and those of a hybrid stack, YPB750, in which two YBCO bulk annuli, each Ø46 mm and 16-mm thick with a 25-mm bore, are added to YP750, one at the top and the other at the bottom. © 2011 IEEE.","2011","2016-04-04 17:51:10","2016-04-04 17:51:10","","1632-1635","","3 PART 2","21","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/QUSN7GRQ/display.html","","","Compact NMR; Field cooling; Field homogeneity; Optimization; Temporal stability; Trapped field; YBCO plates","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2UTB3RX","journalArticle","1988","Petrescu, G.","OPTIMIZATION TECHNIQUES FOR SIMULATION PROGRAMS.","Advances in modelling & simulation","","0761-2494","","","To minimize computing time, among the P programs generating artificial statistical selection x(t), t epsilon left bracket 0, T right bracket , x epsilon X, (X the set of variables of state of the simulated system), those minimizing an objective function f(P) will be chosen. Considering the oriented graph of influences between variables of state G equals (X, GAMMA ), existence theorems for programs reaching the minimum of f are stated. A programming model for optimal organization of memory in reference to function f is also given.","1988","2016-04-04 17:51:10","2016-04-04 17:51:10","","1-13","","2","12","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/BISDJ2J2/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FFQXF4BH","journalArticle","2011","Rossi, L.; Rumley, L.; Ort, C.; Minkkinen, P.; Barry, D.A.; Chèvre, N.","Samplinghelper a web-based tool to assess the reliability of sampling strategies in sewers and receiving waters","Water Science and Technology","","0273-1223","10.2166/wst.2011.177","","Sampling is a key step in the analysis of chemical compounds. It is particularly important in the environmental field, for example for wastewater effluents, wet-weather discharges or streams in which the flows and concentrations vary greatly over time. In contrast to the improvements that have occurred in analytical measurement, developments in the field of sampling are less active. However, sampling errors may exceed by an order of magnitude those related to analytical processes. We proposed an Internet-based application based on a sampling theory to identify and quantify the errors in the process of taking samples. This general theory of sampling, already applied to different areas, helps to answer questions related to the number of samples, their volume, their representativeness, etc. The use of the internet to host this application facilitates use of theoretical tools and raise awareness of the uncertainties related to sampling. An example is presented, which highlights the importance of the sampling step in the quality of analytical results. © IWA Publishing 2011.","2011","2016-04-04 17:51:10","2016-04-04 17:51:10","","2975-2982","","12","63","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/TXJ7JEVE/display.html","","","Errors; Heterogeneity; Reliability; Sampling; Uncertainties","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FMRAF5H9","conferencePaper","2013","Shafiee, S.; Kamangar, F.; Athitsos, V.; Huang, J.","The role of dictionary learning on sparse representation-based classification","","978-1-4503-1973-7","","10.1145/2504335.2504385","","This paper analyzes the role of dictionary selection in Sparse Representation-based Classification (SRC). While SRC introduces interesting results in the field of classification, its performance is highly limited by the number of training samples to form the classification matrix. Different studies addressed this issue by using a more compact representation of the training data in order to achieve higher classification speed and accuracy. Representative selection methods which are analyzed in this paper include Metaface dictionary learning, Fisher Discriminative Dictionary Learning (FDDL), Sparse Modeling Representative Selection (SMRS), and random selection of the training samples. The first two methods build their own dictionaries via an optimization process while the other two methods select the representatives directly from the original training samples. These methods, along with the original method which uses all training samples to form the classification matrix, were examined on two face datasets and one digit dataset. The role of feature extraction was also studied using two dimensionality reduction methods, down-sampling and random projection. The results show that the FDDL method leads to the best classification accuracy followed by the SMRS method as the second best. On the other hand, the SMRS method requires a much smaller learning time which makes it more appropriate for dynamic situations where the dictionary is regularly updated with new samples. The accuracy of the Metaface dictionary learning method was specifically less than the other two methods. As expected, using all the training samples as the dictionary resulted in the best recognition rates in all the datasets but the classification times for this approach were far larger than the required time using any of the three dictionary learning methods. © 2013 ACM.","2013","2016-04-04 17:48:05","2016-04-04 17:48:05","","","","","","","","","","","","","","","English","","","Scopus","","Scopus","","DOI: 10.1145/2504335.2504385","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/URMHI952/display.html","","","Fisher discriminative dictionary learning; metaface learning; sparse modeling representative selection; sparse representation-based classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM International Conference Proceeding Series","","","","","","","","","","","","","","",""
"G3B3HT9P","journalArticle","2011","Mathiassen, J.R.; Misimi, E.; Bondø, M.; Veliyulin, E.; Østvik, S.O.","Trends in application of imaging technologies to inspection of fish and fish products","Trends in Food Science and Technology","","0924-2244","10.1016/j.tifs.2011.03.006","","Applications of imaging technologies are playing an important role in several major areas in research and industry, including process optimization, automated sorting and grading, and automated processing. This review looks at the trends in application of imaging technologies to inspection of fish and fish products - in particular reviewing the applications of VIS/NIR imaging, VIS/NIR imaging spectroscopy, planar and computed tomography (CT) X-ray imaging, and magnetic resonance imaging (MRI). In recent years, a large amount of research has been published on the use of imaging technologies for inspecting fish and fish products. This review article condenses a representative selection of recent research and industrial solutions in order to observe the general trends in how the imaging technologies are applied to inspection of fish and fish products. Based on these observed trends, we provide some viewpoints on the current situation and suggestions for future research directions. © 2011 Elsevier Ltd.","2011","2016-04-04 17:48:05","2016-04-04 17:48:05","","257-275","","6","22","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/5RVR6NNB/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GFNMN8I8","journalArticle","2004","Ólafsson, S.","Two-stage nested partitions method for stochastic optimization","Methodology and Computing in Applied Probability","","1387-5841","10.1023/B:MCAP.0000012413.54789.cc","","We address the problem of optimizing over a large but finite set when the objective function does not have an analytical expression and is evaluated using noisy estimation. Building on the recently proposed nested partitions method for stochastic optimization, we develop a new approach that combines this random search method and statistical selection for guiding the search. We prove asymptotic convergence and analyze the finite time behavior of the new approach. We also report extensive numerical results to illustrate the benefits of the new approach. © 2004 Kluwer Academic Publishers.","2004","2016-04-04 17:51:10","2016-04-04 17:51:10","","5-27","","1","6","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/9PWHCEXH/display.html","","","Random search; Simulation; statistical selection; Stochastic optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJQ2XWCX","journalArticle","2006","Posada, D.","ModelTest Server: A web-based tool for the statistical selection of models of nucleotide substitution online","Nucleic Acids Research","","0305-1048","10.1093/nar/gkl042","","ModelTest server is a web-based application for the selection of models of nucleotide substitution using the program ModelTest. The server takes as input a text file with likelihood scores for the set of candidate models. Models can be selected with hierarchical likelihood ratio tests, or with the Akaike or Bayesian information criteria. The output includes several statistics for the assessment of model selection uncertainty, for model averaging or to estimate the relative importance of model parameters. The server can be accessed at http://darwin.uvigo.es/ software/modeltest_server.html. © The Author 2006. Published by Oxford University Press. All rights reserved.","2006","2016-04-04 17:51:10","2016-04-04 17:51:10","","W700-W703","","WEB. SERV. ISS.","34","","","ModelTest Server","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/BIBGXZI3/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GN5ERMZV","journalArticle","2015","Kim, D.; Wang, W.; Tetteh, M.; Liang, J.; Park, S.; Lee, W.","Biased respondent group selection under limited budget for minority opinion survey","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","0302-9743","10.1007/978-3-319-21786-4_16","","This paper discusses a new approach to use the information from a special social network with high homophily to select a survey respondent group under a limited budget such that the result of the survey is biased to the minority opinions. This approach has a wide range of potential applications, e.g. collecting complaints from the customers of a new product while most of them are satisfied. We formally define the problem of computing such group with better utilization as the p-biased representative selection problem (p-BRSP). This problem has two separate objectives and is difficult to deal with. Thus, we also propose a new unified-objective which is a function of the two optimization objectives. Most importantly, we introduce two polynomial time heuristic algorithms for the problem, where each of which has an approximation ratio with respect to each of the objectives. © Springer International Publishing Switzerland 2015.","2015","2016-04-04 17:48:05","2016-04-04 17:48:05","","182-192","","","9197","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/WR639CF6/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HCPNA4ID","journalArticle","2015","Premalatha, N.; Gopal, N.O.; Jose, P.A.; Anandham, R.; Kwon, S.-W.","Optimization of cellulase production by Enhydrobacter sp. ACCA2 and its application in biomass saccharification","Frontiers in Microbiology","","1664-302X","10.3389/fmicb.2015.01046","","Cellulase finds use in saccharification of lignocellulosic agroresidues to fermentable sugars which can be used for production of commercially important metabolites. This study reports endoglucanase (CMCase) production by Enhydrobacter sp. ACCA2. The CMCase activity of the strain ACCA2 was successively improved by optimization of range of physical and nutritional parameter in a set of non-statistical and statistical experiments. Initial non-statistical selection of carbon source, incubation time, temperature and pH resulted in 1.07 fold increase of CMCase activity. In a subsequent statistical method, response surface methodology, optimization of medium components such as carboxymethylcellulose, peptone, NaCl, MgSO4, K2HPO4, and (NH4)2SO4 yielded further increase up to 2.39 fold CMCase activity. The cellulolytic potential was evaluated in biomass saccharification with different plant materials and the results revealed that the enzyme produced by strain may have significant commercial values for industrial saccharification process. Moreover, this is the first report of cellulase production by an Enhydrobacter spp. © 2015 Premalatha, Gopal, Jose, Anandham and Kwon.","2015","2016-04-04 17:51:10","2016-04-04 17:51:10","","","","OCT","6","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/RZT6WNFQ/display.html","","","Carboxy methyl cellulose; Cellulase; Central composite design; Response surface methodology; Saccharification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HI5QRHC3","journalArticle","2013","Willett, W.; Ginosar, S.; Steinitz, A.; Hartmann, B.; Agrawala, M.","Identifying redundancy and exposing provenance in crowdsourced data analysis","IEEE Transactions on Visualization and Computer Graphics","","1077-2626","10.1109/TVCG.2013.164","","We present a system that lets analysts use paid crowd workers to explore data sets and helps analysts interactively examine and build upon workers' insights. We take advantage of the fact that, for many types of data, independent crowd workers can readily perform basic analysis tasks like examining views and generating explanations for trends and patterns. However, workers operating in parallel can often generate redundant explanations. Moreover, because workers have different competencies and domain knowledge, some responses are likely to be more plausible than others. To efficiently utilize the crowd's work, analysts must be able to quickly identify and consolidate redundant responses and determine which explanations are the most plausible. In this paper, we demonstrate several crowd-assisted techniques to help analysts make better use of crowdsourced explanations: (1) We explore crowd-assisted strategies that utilize multiple workers to detect redundant explanations. We introduce color clustering with representative selection-a strategy in which multiple workers cluster explanations and we automatically select the most-representative result-and show that it generates clusterings that are as good as those produced by experts. (2) We capture explanation provenance by introducing highlighting tasks and capturing workers' browsing behavior via an embedded web browser, and refine that provenance information via source-review tasks. We expose this information in an explanation-management interface that allows analysts to interactively filter and sort responses, select the most plausible explanations, and decide which to explore further. © 2013 IEEE.","2013","2016-04-04 17:48:05","2016-04-04 17:48:05","","2198-2206","","12","19","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/IKWES3WP/display.html","","","crowdsourcing; Social Data Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQQ55RQ5","journalArticle","2011","Huang, Z.; Xiang, Y.; Zhang, B.; Liu, X.","A clustering based approach for skyline diversity","Expert Systems with Applications","","0957-4174","10.1016/j.eswa.2010.12.104","","Skyline query processing has recently received a lot of attention in database and data-mining communities. To the best of our knowledge, the existing researches mainly focus on considering how to efficiently return the whole skyline set. However, when the cardinality and dimensionality of input objects increase, the number of skylines grows exponentially, and hence this ""huge"" skyline set is completely useless to users. On the other hand, in most real applications, the objects are usually clustered, and therefore many objects have similar attribute values. Motivated by the above facts, in this paper, we present a novel type of SkyCluster query to capture the skyline diversity and improve the usefulness of skyline result. The SkyCluster query integrates K-means clustering into skyline computation, and returns K ""representative"" and ""diverse"" skyline objects to users. To process such query, a straightforward approach is to simply integrate the existing techniques developed for skyline-only and clustering-only together. But this approach is costly since both skyline computation and K-means clustering are all CPU-sensitive. We propose an efficient evaluation approach which is based on the circinal index to seamlessly integrate subspace skyline computation, K-means clustering and representatives selection. Also, we present a novel optimization heuristic to further improve the query performance. Experimental study shows that our approach is both efficient and effective. © 2011 Elsevier Ltd. All rights reserved.","2011","2016-04-04 17:48:05","2016-04-04 17:48:05","","7984-7993","","7","38","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/PUHZCKTQ/display.html","","","Circinal index; Diversity; K-means clustering; Performance evaluation; Skyline query","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HUQJV2MP","journalArticle","2014","Protopapadakis, E.; Doulamis, A.; Matsatsinis, N.","Semi-supervised image meta-filtering in cultural heritage applications","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","0302-9743","10.1007/978-3-319-13695-0","","An image filtering scheme for images of cultural interest is presented. The model utilize a semi supervised approach for the creation of an appropriate distance learning metric, which is used for the filtering. User’s feedback is involved only for a minor set of data, defined using optics algorithm and sparse modeling representative selection. Such approach facilitates the refinement of retrieval results always under the scope of the end user needs. © Springer International Publishing Switzerland 2014.","2014","2016-04-04 17:48:05","2016-04-04 17:48:05","","102-110","","","8740","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/UMVXU3FD/display.html","","","Cultural heritage; Hierarchical clustering; Semi supervised learning; Sparse modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IBXXQJ7M","journalArticle","2010","Epperson, B.K.; McRae, B.H.; Scribner, K.; Cushman, S.A.; Rosenberg, M.S.; Fortin, M.-J.; James, P.M.A.; Murphy, M.; Manel, S.; Legendre, P.; Dale, M.R.T.","Utility of computer simulations in landscape genetics","Molecular Ecology","","0962-1083","10.1111/j.1365-294X.2010.04678.x","","Population genetics theory is primarily based on mathematical models in which spatial complexity and temporal variability are largely ignored. In contrast, the field of landscape genetics expressly focuses on how population genetic processes are affected by complex spatial and temporal environmental heterogeneity. It is spatially explicit and relates patterns to processes by combining complex and realistic life histories, behaviours, landscape features and genetic data. Central to landscape genetics is the connection of spatial patterns of genetic variation to the usually highly stochastic space-time processes that create them over both historical and contemporary time periods. The field should benefit from a shift to computer simulation approaches, which enable incorporation of demographic and environmental stochasticity. A key role of simulations is to show how demographic processes such as dispersal or reproduction interact with landscape features to affect probability of site occupancy, population size, and gene flow, which in turn determine spatial genetic structure. Simulations could also be used to compare various statistical methods and determine which have correct type I error or the highest statistical power to correctly identify spatio-temporal and environmental effects. Simulations may also help in evaluating how specific spatial metrics may be used to project future genetic trends. This article summarizes some of the fundamental aspects of spatial-temporal population genetic processes. It discusses the potential use of simulations to determine how various spatial metrics can be rigorously employed to identify features of interest, including contrasting locus-specific spatial patterns due to micro-scale environmental selection. © 2010 Blackwell Publishing Ltd.","2010","2016-04-04 17:51:10","2016-04-04 17:51:10","","3549-3564","","17","19","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/I7SHQKW4/display.html","","","individual-based models; landscape ecology; population genetics; simulations; spatial statistics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IN6R5GI7","conferencePaper","2006","","Proceedings of the 2006 Winter Simulation Conference, WSC","","978-1-4244-0501-5","","","","The proceedings contain 296 papers. The topics discussed include: spreadsheet simulation; introduction to modeling and generating probabilistic input processes for simulation; output analysis for simulations; tips for the successful practice of simulation; black-box algorithms for sampling from continuous distributions; splitting for rare-event simulation; a comprehensive review of methods for simulation output analysis; selection and multiple-comparison procedures for regenerative systems; integration of statistical selection with search mechanism for solving multi-objective simulation-optimization problems; efficient simulation of population overflow in parallel queues; the impact of ordinal on response surface methodology; allocating field service teams with simulation in energy/utilities environment; simulation results for supply chain configurations based on information sharing; and efficient importance for reduced form models in credit risk.","2006","2016-04-04 17:51:10","2016-04-04 17:51:10","","","","","","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/JWIJ2AB4/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - Winter Simulation Conference","","","","","","","","","","","","","","",""
"KDGJNF6J","journalArticle","2012","Brandmaier, S.; Tetko, I.V.; Öberg, T.","An evaluation of experimental design in QSAR modelling utilizing the k-medoid clustering","Journal of Chemometrics","","0886-9383","10.1002/cem.2459","","A reliable selection of a representative subset of chemical compounds has been reported to be crucial for numerous tasks in computational chemistry and chemoinformatics. We investigated the usability of an approach on the basis of the k-medoid algorithm for this task and in particular for experimental design and the split between training and validation set. We therefore compared the performance of models derived from such a selection to that of models derived using several other approaches, such as space-filling design and D-optimal design. We validated the performance on four datasets with different endpoints, representing toxicity, physicochemical properties and others. Compared with the models derived from the compounds selected by the other examined approaches, those derived with the k-medoid selection show a high reliability for experimental design, as their performance was constantly among the best for all examined datasets. Of all the models derived with all examined approaches, those derived with the k-medoid approach were the only ones that showed a significantly improved performance compared with a random selection, for all datasets, the whole examined range of selected compounds and for each dimensionality of the search space. © 2012 John Wiley & Sons, Ltd.","2012","2016-04-04 17:48:05","2016-04-04 17:48:05","","509-517","","10","26","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/WNAQ535T/display.html","","","Design of experiments; Drug design; REACH; Representative selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KS4RPCWR","conferencePaper","2013","Conze, P.-H.; Crivelli, T.; Robert, P.; Morin, L.","Dense motion estimation between distant frames: Combinatorial multi-step integration and statistical selection","","978-1-4799-2341-0","","10.1109/ICIP.2013.6738795","","Accurate estimation of dense point correspondences between two distant frames of a video sequence is a challenging task. To address this problem, we present a combinatorial multistep integration procedure which allows one to obtain a large set of candidate motion fields between the two distant frames by considering multiple motion paths across the video sequence. Given this large candidate set, we propose to perform the optimal motion vector selection by combining a global optimization stage with a new statistical processing. Instead of considering a selection only based on intrinsic motion field quality and spatial regularization, the statistical processing exploits the spatial distribution of candidates and introduces an intra-candidate quality based on forward-backward consistency. Experiments evaluate the effectiveness of our method for distant motion estimation in the context of video editing. © 2013 IEEE.","2013","2016-04-04 17:51:10","2016-04-04 17:51:10","","3860-3864","","","","","","Dense motion estimation between distant frames","","","","","","","English","","","Scopus","","Scopus","","DOI: 10.1109/ICIP.2013.6738795","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/X3ZWM5VB/display.html","","","dense point matching; distant frames; motion estimation; statistical analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2013 IEEE International Conference on Image Processing, ICIP 2013 - Proceedings","","","","","","","","","","","","","","",""
"NAVX9MAF","journalArticle","2007","Alrefaei, M.H.; Almomani, M.","Subset selection of best simulated systems","Journal of the Franklin Institute","","0016-0032","10.1016/j.jfranklin.2006.02.020","","In this paper, we consider the problem of selecting a subset of k systems that is contained in the set of the best s simulated systems when the number of alternative systems is huge. We propose a sequential method that uses the ordinal optimization to select a subset G randomly from the search space that contains the best simulated systems with high probability. To guarantee that this subset contains the best systems it needs to be relatively large. Then methods of ranking and selections will be applied to select a subset of k best systems of the subset G with high probability. The remaining systems of G will be replaced by newly selected alternatives from the search space. This procedure is repeated until the probability of correct selection (a subset of the best k simulated systems is selected) becomes very high. The optimal computing budget allocation is also used to allocate the available computing budget in a way that maximizes the probability of correct selection. Numerical experiments for comparing these algorithms are presented. © 2006 The Franklin Institute.","2007","2016-04-04 17:51:10","2016-04-04 17:51:10","","495-506","","5","344","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/CVFGRA77/display.html","","","Ordinal optimization; Ranking and selection; Simulation optimization; statistical selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NE8MSBNQ","journalArticle","2009","Bacchetti, P.; Boylan, R.","Estimating complex multi-state misclassification rates for biopsy-measured liver fibrosis in patients with hepatitis C","International Journal of Biostatistics","","1557-4679","10.2202/1557-4679.1139","","For both clinical and research purposes, biopsies are used to classify liver damage known as fibrosis on an ordinal multi-state scale ranging from no damage to cirrhosis. Misclassification can arise from reading error (misreading of a specimen) or sampling error (the specimen does not accurately represent the liver). Studies of biopsy accuracy have not attempted to synthesize these two sources of error or to estimate actual misclassification rates from either source. Using data from two studies of reading error and two of sampling error, we find surprisingly large possible misclassification rates, including a greater than 50% chance of misclassification for one intermediate stage of fibrosis. We find that some readers tend to misclassify consistently low or consistently high, and some specimens tend to be misclassified low while others tend to be misclassified high. Non-invasive measures of liver fibrosis have generally been evaluated by comparison to simultaneous biopsy results, but biopsy appears to be too unreliable to be considered a gold standard. Non-invasive measures may therefore be more useful than such comparisons suggest. Both stochastic uncertainty and uncertainty about our model assumptions appear to be substantial. Improved studies of biopsy accuracy would include large numbers of both readers and specimens, greater effort to reduce or eliminate reading error in studies of sampling error, and careful estimation of misclassification rates rather than less useful quantities such as kappa statistics. Copyright ©2009 The Berkeley Electronic Press. All rights reserved.","2009","2016-04-04 17:51:10","2016-04-04 17:51:10","","","","1","5","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/3RJHCDWH/display.html","","","Fibrosis; Hepatitis C; Kappa statistic; Latent variables; Misclassification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P6D8Q3FF","journalArticle","2010","Chu, W.-T.; Lin, C.-H.","Consumer photo management and browsing facilitated by near-duplicate detection with feature filtering","Journal of Visual Communication and Image Representation","","1047-3203","10.1016/j.jvcir.2010.01.006","","Near-duplicate detection techniques are exploited to facilitate representative photo selection and region-of-interest (ROI) determination, which are important functionalities for efficient photo management and browsing. To make near-duplicate detection module resist to noisy features, three filtering approaches, i.e., point-based, region-based, and probabilistic latent semantic (pLSA), are developed to categorize feature points. For the photos taken in travels, we construct a support vector machine classifier to model matching patterns between photos and determine whether photos are near-duplicate pairs. Relationships between photos are then described as a graph, and the most central photo that best represents a photo cluster is selected according to centrality values. Because matched feature points are often located in the interior or at the contour of important objects, the region that compactly covers the matched feature points is determined as the ROI. We compare the proposed approaches with conventional ones and demonstrate their effectiveness. © 2010 Elsevier Inc. All rights reserved.","2010","2016-04-04 17:48:05","2016-04-04 17:48:05","","256-268","","3","21","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/3CN8P6SE/display.html","","","Feature filtering; Image clustering; Near-duplicate detection; Photo management and browsing; Photo summarization; Probabilistic latent semantic analysis; Region-of-interest; Representative selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PMJXT6ZU","journalArticle","2014","Diepens, N.J.; Arts, G.H.P.; Brock, T.C.M.; Smidt, H.; Van, Den Brink; Van, Den Heuvel-Greve; Koelmans, A.A.","Sediment toxicity testing of organic chemicals in the context of prospective risk assessment: A review","Critical Reviews in Environmental Science and Technology","","1064-3389","10.1080/01496395.2012.718945","","Sediment toxicity tests play an important role in prospective risk assessment for organic chemicals. This review describes sediment toxicity tests for microorganisms, macrophytes, benthic invertebrates, and benthic communities. Current approaches in sediment toxicity testing are fragmentary and diverse. This hampers the translation of single-species test results between freshwater, estuarine and marine ecosystems and to the population and community levels. A more representative selection of species and endpoints as well as a unification of dose metrics and exposure assessment methodologies across groups of test species, constitutes a first step toward a balanced strategy for sediment toxicity testing of single organic compounds in the context of prospective risk assessment. Supplementary materials are available for this article. Go to the publisher's online edition of Critical Reviews in Environmental Science and Technology for the supplemental material. © 2014 Taylor and Francis Group, LLC.","2014","2016-04-04 17:48:05","2016-04-04 17:48:05","","255-302","","3","44","","","Sediment toxicity testing of organic chemicals in the context of prospective risk assessment","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/V3FIH278/display.html","","","benthic community; benthic invertebrates; macrophytes; microorganisms; prospective sediment toxicity testing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4Q36WMU","journalArticle","2013","Li, A.-Z.; Ren, R.-E.; Dong, J.-C.","Mean-variance-entropy fuzzy portfolio selection based on integrated forecast","Xitong Gongcheng Lilun yu Shijian/System Engineering Theory and Practice","","1000-6788","","","In this paper a fuzzy portfolio selection optimization decision based on a combination of forecasting model is constructed, representative selection of the genetic neural network model, multi-factor SVM regression model and ARIMA time series model as a combination of a single model for forecasting. This paper establishes possibilistic mean-variance-entropy portfolio selection model in which a single model to predict the result is treated as fuzzy variable, the empirical results show that the possibilistic meanvariance-entropy portfolio selection model can obtain higher yield and lower relative risk. The methodology of this paper is useful in such practice as fund management, financial risk management. It is hoped that the methodology can improve the scientific level of decision making.","2013","2016-04-04 17:48:05","2016-04-04 17:48:05","","1116-1125","","5","33","","","","","","","","","","Chinese","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/U9GXN9BH/display.html","","","Fuzzy portfolio selection; Integrated forecast; Mean-variance-entropy model; Optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QKWSPU6G","journalArticle","2009","Chashchukhin, I.S.; Votyakov, S.L.","Behavior of iron-group elements, oxybarometry, and genesis of unique chromite deposits in the Kempirsai massif","Geology of Ore Deposits","","1075-7015","10.1134/S1075701509020044","","Ultramafic rocks and high-Cr chromite ore from the Almaz-Zhemchuzhina deposit, the largest in the Main ore field of the Kempirsai massif, have been studied. The detailed mineralogical and geochemical examination of deep structure test and exploratory boreholes allowed us to establish the rough stratification of ultramafic rocks and to demonstrate the position of unique chromite deposits in the generalized vertical section of the southeastern Kempirsai massif. From top to bottom, a barren harzburgite-lherzolite series gives way to an ore-bearing dunite-harzburgite complex with the largest chromite deposits, including the unique Almaz-Zhemchuzhina deposit, in its upper portion and then to pyroxene-free dunite densely impregnated with chromite in the upper part and containing sparsely disseminated chromite at its base. The lower unit is composed of a barren lherzolite-harzburgite series transformed into blastomylonites near the contact with dunite, suggesting a tectonically doubled section in the southeastern part of the massif. The synore asymmetric geochemical zoning developed in the course of formation of chromite deposits as a result of removal of oreforming iron-group elements from the underlying and wall ultramafic rocks into the overlying rocks. Host rocks with disturbed initial proportions of Cr, Fe, Ni, and Mn, together with orebodies, made up ore-bearing zones no less than 1 km in thickness and subdivided into supra-, inter-, and subore subzones. The subore and wall rocks are characterized by partial loss (wt %) of Cr2O3(0.1), NiO (0.04), FeOtot(0.5), and MnO (0.02) and their removal into the interore and supraore (0.03 NiO) subzones. Thus, the subore ultramafic rocks served as a source of ore-forming components, while the interore zone with orebodies occurring therein served as a zone of discharge of these components. Using Mössbauer spectroscopy, the crystal chemistry of iron ions was studied in a representative selection of Cr-spinel samples from rocks and ores of the southeastern and western blocks (the Almaz-Zhemchuzhina and Geophysical XII deposits). The degree of iron oxidation in the samples varies from 8 to 33%. In most cases, a difference in degree of iron oxidation is established in stoichiometric approximation and from Mössbauer data. In other words, the integral stoichiometry of ferrous and ferric ions is disturbed. Such a disturbance may be related not only to partial inversion of the Cr-spinel structure but also to local heterogeneity of the mineral at the micro- and nanolevels with clustering of cations and formation of their associates. An empirical correction of the olivine-Cr-spinel geothermometer and oxybarometer has been performed. The inverse correlation between oxygen fugacity and degree of depletion of ultramafic rocks indicates that these rocks were formed in a closed system with participation of a water-methane fluid. Along with stratification of ultramafics, this correlation testifies to a powerful asthenospheric source of reduced fluids. The retention of low oxygen fugacity in central portions of orebodies does not rule out that after a break this source participated in the formation of unique chromite deposits in the Kempirsai massif. © Pleiades Publishing, Ltd. 2009.","2009","2016-04-04 17:48:05","2016-04-04 17:48:05","","123-138","","2","51","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/CWACRRAF/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QQKDQ42D","journalArticle","2012","Haddad, K.; Rahman, A.","Regional flood frequency analysis in eastern Australia: Bayesian GLS regression-based methods within fixed region and ROI framework - Quantile Regression vs. Parameter Regression Technique","Journal of Hydrology","","0022-1694","10.1016/j.jhydrol.2012.02.012","","In this article, an approach using Bayesian Generalised Least Squares (BGLS) regression in a region-of-influence (ROI) framework is proposed for regional flood frequency analysis (RFFA) for ungauged catchments. Using the data from 399 catchments in eastern Australia, the BGLS-ROI is constructed to regionalise the flood quantiles (Quantile Regression Technique (QRT)) and the first three moments of the log-Pearson type 3 (LP3) distribution (Parameter Regression Technique (PRT)). This scheme firstly develops a fixed region model to select the best set of predictor variables for use in the subsequent regression analyses using an approach that minimises the model error variance while also satisfying a number of statistical selection criteria. The identified optimal regression equation is then used in the ROI experiment where the ROI is chosen for a site in question as the region that minimises the predictive uncertainty. To evaluate the overall performances of the quantiles estimated by the QRT and PRT, a one-at-a-time cross-validation procedure is applied. Results of the proposed method indicate that both the QRT and PRT in a BGLS-ROI framework lead to more accurate and reliable estimates of flood quantiles and moments of the LP3 distribution when compared to a fixed region approach. Also the BGLS-ROI can deal reasonably well with the heterogeneity in Australian catchments as evidenced by the regression diagnostics. Based on the evaluation statistics it was found that both BGLS-QRT and PRT-ROI perform similarly well, which suggests that the PRT is a viable alternative to QRT in RFFA. The RFFA methods developed in this paper is based on the database available in eastern Australia. It is expected that availability of a more comprehensive database (in terms of both quality and quantity) will further improve the predictive performance of both the fixed and ROI based RFFA methods presented in this study, which however needs to be investigated in future when such a database is available. © 2012 Elsevier B.V.","2012","2016-04-04 17:51:10","2016-04-04 17:51:10","","142-161","","","430-431","","","Regional flood frequency analysis in eastern Australia","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/WVMAIANA/display.html","","","Bayesian method; Generalised Least Squares Regression; Parameter Regression; Quantile Regression; Regional flood frequency analysis; Region-of-influence approach","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QTMNMRQE","journalArticle","1999","Zheng, W.; Cho, S.J.; Waller, C.L.; Tropsha, A.","Rational combinatorial library design. 3. Simulated annealing guided evaluation (SAGE) of molecular diversity: A novel computational tool for universal library design and database mining","Journal of Chemical Information and Computer Sciences","","0095-2338","10.1021/ci980103p","","We have developed a novel method for molecular diversity sampling called SAGE (simulated annealing guided evaluation of molecular diversity). Compounds in chemical databases or virtual combinatorial libraries are conventionally represented as points in multidimensional descriptor space. The SAGE algorithm selects a desired number of optimally diverse points (compounds) from a database. The diversity of a subset of points is measured by a specially designed diversity function, and the most diverse subset is selected using Simulated Annealing (SA) as the optimization tool. Application of SAGE to two simulated data sets of randomly distributed points in two-dimensional space afforded diverse and representative selection as judged by visual inspection. SAGE was also applied, in comparison with random sampling, to two other simulated data sets with points distributed among many clusters. We found that SAGE sampling covered significantly more clusters than the random sampling. By defining a fraction of data points as active, we also compared SAGE with random sampling in terms of hit rates. We showed that when the percentage of active points was low, the hit rates obtained by SAGE were always higher than those obtained by random sampling. When the percentage of active points was high, the performance of SAGE, in terms of individual hit rates, depended upon the data structure. However, in all cases, SAGE performed better than random sampling when cluster hit rates were used as the criterion.","1999","2016-04-04 17:48:05","2016-04-04 17:48:05","","738-746","","4","39","","","Rational combinatorial library design. 3. Simulated annealing guided evaluation (SAGE) of molecular diversity","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/6HUG8NQH/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R5HIB9IK","journalArticle","2012","Dolgui, A.; Kovalev, S.","Min-max and min-max (relative) regret approaches to representatives selection problem","4OR","","1619-4500","10.1007/s10288-012-0202-3","","The following optimization problem is studied. There are several sets of integer positive numbers whose values are uncertain. The problem is to select one representative of each set such that the sum of the selected numbers is minimum. The uncertainty is modeled by discrete and interval scenarios, and the min-max and min-max (relative) regret approaches are used for making a selection decision. The arising min-max, min-max regret and min-max relative regret optimization problems are shown to be polynomially solvable for interval scenarios. For discrete scenarios, they are proved to be NP-hard in the strong sense if the number of scenarios is part of the input. If it is part of the problem type, then they are NP-hard in the ordinary sense, pseudo-polynomially solvable by a dynamic programming algorithm and possess an FPTAS. This study is motivated by the problem of selecting tools of minimum total cost in the design of a production line. © 2012 Springer-Verlag.","2012","2016-04-04 17:48:05","2016-04-04 17:48:05","","181-192","","2","10","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/XHMZMVHR/display.html","","","Computational complexity; Dynamic programming; Min-max approach; Min-max regret; Uncertainty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R7RRGBIV","journalArticle","2006","Sun, X.-Y.; Gong, D.-W.; Hao, G.-S.","Representative selection for cooperative co-evolutionary genetic algorithms","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","0302-9743","","","The performance of cooperative co-evolutionary genetic algorithms is highly affected by the representative selection strategy. But rational method is absent now. Oriented to the shortage, the representative selection strategy is studied based on the parallel implementation of cooperative co-evolutionary genetic algorithms in LAN. Firstly, the active cooperation ideology for representative selection and the dynamical determinate method on cooperation pool size are put forward. The methods for determining cooperation pool size, selecting cooperators and permuting cooperations are presented based on the evolutionary ability of sub-population and distributive performance of the individuals. Thirdly, the implementation steps are given. Lastly, the results of benchmark functions optimization show the validation of the method. © Springer-Verlag Berlin Heidelberg 2006.","2006","2016-04-04 17:48:05","2016-04-04 17:48:05","","18-25","","","4247 LNCS","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/ZUBIZVSP/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RC7BXD7E","journalArticle","2007","Chatziioannou, A.; Moulos, P.","ANDROMEDA: A MATLAB automated cDNA microarray data analysis platform","IFIP International Federation for Information Processing","","1571-5736","10.1007/978-0-387-74161-1_14","","DNA microarrays constitute a relatively new biological technology which allows gene expression profiling at a global level by measuring mRNA abundance. However, the grand complexity characterizing a microarray experiment entails the development of computationally powerful tools apt for probing the biological problem studied. ANDROMEDA (Automated aND RObust Microarray Experiment Data Analysis) is a MATLAB implemented program which performs all steps of typical microarray data analysis including noise filtering processes, background correction, data normalization, statistical selection of differentially expressed genes based on parametric or non parametric statistics and hierarchical cluster analysis resulting in detailed lists of differentially expressed genes and formed clusters through a strictly defined automated workflow. Along with the completely automated procedure, ANDROMEDA offers a variety of visualization options (MA plots, boxplots, clustering images etc). Emphasis is given to the output data format which contains a substantial amount of useful information and can be easily imported in a spreadsheet supporting software or incorporated in a relational database for further processing and data mining. © 2007 International Federation for Information Processing.","2007","2016-04-04 17:51:10","2016-04-04 17:51:10","","127-136","","","247","","","ANDROMEDA","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/V2HIIGW6/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RCCH6TCR","journalArticle","2015","Allen, J.T.; Croom, S.M.; Konstantopoulos, I.S.; Bryant, J.J.; Sharp, R.; Cecil, G.N.; Fogarty, L.M.R.; Foster, C.; Green, A.W.; Ho, I.-T.; Owers, M.S.; Schaefer, A.L.; Scott, N.; Bauer, A.E.; Baldry, I.; Barnes, L.A.; Bland-Hawthorn, J.; Bloom, J.V.; Brough, S.; Colless, M.; Cortese, L.; Couch, W.J.; Drinkwater, M.J.; Driver, S.P.; Goodwin, M.; Gunawardhana, M.L.P.; Hampton, E.J.; Hopkins, A.M.; Kewley, L.J.; Lawrence, J.S.; Leon-Saval, S.G.; Liske, J.; López-Sánchez, Á.R.; Lorente, N.P.F.; McElroy, R.; Medling, A.M.; Mould, J.; Norberg, P.; Parker, Q.A.; Power, C.; Pracy, M.B.; Richards, S.N.; Robotham, A.S.G.; Sweet, S.M.; Taylor, E.N.; Thomas, A.D.; Tonini, C.; Walcher, C.J.","The SAMI Galaxy Survey: Early Data Release","Monthly Notices of the Royal Astronomical Society","","0035-8711","10.1093/mnras/stu2057","","We present the Early Data Release of the Sydney-AAOMulti-object Integral field spectrograph (SAMI) Galaxy Survey. The SAMI Galaxy Survey is an ongoing integral field spectroscopic survey of ~3400 low-redshift (z < 0.12) galaxies, covering galaxies in the field and in groups within the Galaxy And Mass Assembly (GAMA) survey regions, and a sample of galaxies in clusters. In the Early Data Release, we publicly release the fully calibrated data cubes for a representative selection of 107 galaxies drawn from the GAMA regions, along with information about these galaxies from the GAMA catalogues. All data cubes for the Early Data Release galaxies can be downloaded individually or as a set from the SAMI Galaxy Survey website. In this paper we also assess the quality of the pipeline used to reduce the SAMI data, giving metrics that quantify its performance at all stages in processing the raw data into calibrated data cubes. The pipeline gives excellent results throughout, with typical sky subtraction residuals in the continuum of 0.9-1.2 per cent, a relative flux calibration uncertainty of 4.1 per cent (systematic) plus 4.3 per cent (statistical), and atmospheric dispersion removed with an accuracy of 0.09 arcsec, less than a fifth of a spaxel. © 2014 The Authors. Published by Oxford University Press on behalf of the Royal Astronomical Society.","2015","2016-04-04 17:48:05","2016-04-04 17:48:05","","1567-1583","","2","446","","","The SAMI Galaxy Survey","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/FRH35834/display.html","","","Galaxies: evolution; Galaxies: kinematics and dynamics; galaxies: structure; Techniques: imaging spectroscopy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RD87UVQA","journalArticle","1997","Boberg, J.; Salakoski, T.","Representative noise-free complete-link classification with application to protein structures","Pattern Recognition","","0031-3203","","","In various applications, including many problems of knowledge discovery in databases, and particularly in the field of computational molecular biology, a compact and representative description of a vast object space is desired. In this paper, a constructive mathematical model corresponding the intuitive requirements of representativity is developed. Representativity is divided into two aspects: typicality and comprehensiveness. A new sieving method is presented where a special kind of noise is detected and eliminated by removing anomalous objects from the initial complete linkage partition. The comprehensiveness endangered by sieving is then regained by applying a special completion procedure. Theoretical results ensure that the resulting partition is representative, consisting of solid and separable classes. The conceptual model was further tested by applying the method to protein amino acid sequences of the Brookhaven Protein Data Bank. The recognized biochemical substance of the outcome confirm the representativity of the resulting classification. Published by Elsevier Science Ltd.","1997","2016-04-04 17:48:05","2016-04-04 17:48:05","","467-482","","3","30","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/NTFQ5U9F/display.html","","","Amino acid sequences; Complete linkage clustering; Knowledge discovery in databases; Noise elimination; Non-metric object space; Protein data bank (PDB); Representative selection; Separable partitions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RRUWQFQW","journalArticle","1999","Moretti, S.","Six-jet production at lepton colliders","Nuclear Physics B","","0550-3213","","","We study electron-positron annihilations into six jets at the parton level in perturbative Quantum Chromo-Dynamics (QCD), via the elementary processes e+e- → qq̄gggg, e+e- → qq̄q′q̄′gg and e+e- → qq̄q′q̄′q″q̄″, for massive quarks q, q′ and q″ and massless gluons g. Several numerical results of phenomenological relevance are given, at three different collider energies and for a representative selection of jet clustering algorithms. We also present helicity amplitudes and colour factors needed for the tree-level calculation. © 1999 Elsevier Science B.V.","1999","2016-04-04 17:48:05","2016-04-04 17:48:05","","289-338","","1-2","544","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/DXCIZT4E/display.html","","","Jets; Lepton colliders; LO computations; Perturbative QCD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SHE9JE8N","journalArticle","1988","Berg, O.G.","Selection of dna binding sites by regulatory proteins. Functional specificity and pseudosite competition","Journal of Biomolecular Structure and Dynamics","","0739-1102","10.1080/07391102.1988.10507713","","The frequency of base-pair occurrence in a set of recognition sequences for a particular DNA-binding protein is strongly related to the contributions to the binding free energy from the individual base pairs. Thus from the statistics of base-pair choice, it is possible to estimate the relative binding strengths of any base-pair sequences and to predict the effect of point mutations in specific sites. On the same basis, one can describe the binding properties of random DNA sequences and thereby the expected competitive effects from all the nonspecific DNA sites in the genome of a living cell. The statistical selection theory [Berg & von Hippel, J.Mol. Biol. 193 (1987) 723-750] describing these relations is extended and tested with computer simulations. The theory is shown to hold up well also in the case when base pairs contribute cooperatively to the binding interaction. The simulations also demonstrate the effects of the statistical small-sample uncertainty that appears due to the limited size of all sets of recognition sites identified. © 1988 Taylor & Francis Ltd.","1988","2016-04-04 17:51:10","2016-04-04 17:51:10","","275-297","","2","6","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/P4MNAUVS/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SJZEUPZN","journalArticle","2014","Tehseen, M.; Dumancic, M.; Briggs, L.; Wang, J.; Berna, A.; Anderson, A.; Trowell, S.","Functional coupling of a nematode chemoreceptor to the yeast pheromone response pathway","PLoS ONE","","1932-6203","10.1371/journal.pone.0111429","","Sequencing of the Caenorhabditis elegans genome revealed sequences encoding more than 1,000 G-protein coupled receptors, hundreds of which may respond to volatile organic ligands. To understand how the worm's simple olfactory system can sense its chemical environment there is a need to characterise a representative selection of these receptors but only very few receptors have been linked to a specific volatile ligand. We therefore set out to design a yeast expression system for assigning ligands to nematode chemoreceptors. We showed that while a model receptor ODR-10 binds to C. elegans Ga subunits ODR-3 and GPA-3 it cannot bind to yeast Ga. However, chimaeras between the nematode and yeast Ga subunits bound to both ODR-10 and the yeast Gbc subunits. FIG2 was shown to be a superior MAP-dependent promoter for reporter expression. We replaced the endogenous Ga subunit (GPA1) of the Saccharomyces cerevisiae (ste2D sst2D far1D) triple mutant (""Cyb"") with a Gpa1/ODR-3 chimaera and introduced ODR-10 as a model nematode GPCR. This strain showed concentration-dependent activation of the yeast MAP kinase pathway in the presence of diacetyl, the first time that the native form of a nematode chemoreceptor has been functionally expressed in yeast. This is an important step towards en masse de-orphaning of C. elegans chemoreceptors. © 2014 Tehseen et al.","2014","2016-04-04 17:48:05","2016-04-04 17:48:05","","","","11","9","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/IEF5XHXZ/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T6AVKWB3","journalArticle","1983","Vastola, K.S.; Poor, H.V.","An analysis of the effects of spectral uncertainty on wiener filtering","Automatica","","0005-1098","10.1016/0005-1098(83)90105-X","","A representative selection of results from an extensive study of the performance of Wiener filtering under spectral uncertainty is presented. For a variety of spectral uncertainty models the Wiener filter is shown to have undesirable sensitivity to even small deviations from those signal and noise spectral densities which were used to design the filter. Performance of a robust filter (designed to have the best possible performance when the uncertainty is worst) is also examined. In most cases the robust filter's insensitivity to spectral uncertainty makes it preferable to the traditional Wiener filter. © 1983.","1983","2016-04-04 17:48:05","2016-04-04 17:48:05","","289-293","","3","19","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/2CNTKTPA/display.html","","","Filtering; game theory; smoothing; statistics, robustness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T9BW3RW6","journalArticle","2011","Almomani, M.H.; Rahman, R.A.","The effect of increment in simulation samples on a combined selection procedure","World Academy of Science, Engineering and Technology","","2010-376X","","","Statistical selection procedures are used to select the best simulated system from a finite set of alternatives. In this paper, we present a procedure that can be used to select the best system when the number of alternatives is large. The proposed procedure consists a combination between Ranking and Selection, and Ordinal Optimization procedures. In order to improve the performance of Ordinal Optimization, Optimal Computing Budget Allocation technique is used to determine the best simulation lengths for all simulation systems and to reduce the total computation time. We also argue the effect of increment in simulation samples for the combined procedure. The results of numerical illustration show clearly the effect of increment in simulation samples on the proposed combination of selection procedure.","2011","2016-04-04 17:51:10","2016-04-05 13:34:16","","686-690","","","74","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/6IWU7F4S/display.html; /home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/SSCCMF5C/display.html","","","Indifference-zone; Optimal computing budget allocation; Ordinal optimization; Ranking and selection; Subset selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TD2IUUA2","journalArticle","2014","Witheephanich, K.; Escaño, J. M.; Peña, D. Muñoz de la; Hayes, M. J.","A Min-Max Model Predictive Control Approach to Robust Power Management in Ambulatory Wireless Sensor Networks","IEEE Systems Journal","","1932-8184","10.1109/JSYST.2013.2271388","","This paper addresses the problem of transmission power control within a network of resource-constrained wireless sensors that operate within a particular ambient healthcare environment. Sensor data transmitted to a remote base station within the network arrive subject to node location, orientation, and movement. Power is optimally allocated to all channels using a novel resource efficient algorithm. The proposed algorithm is based on a computationally efficient min-max model predictive controller that uses an uncertain linear state-space model of the tracking error that is estimated via local received signal strength feedback. An explicit solution for the power controller is computed offline using a multiparametric quadratic solver. It is shown that the proposed design leads to a robust control law that can be implemented quite readily on a commercial sensor node platform where computational and memory resources are extremely limited. The design is validated using a fully IEEE 802.15.4 compliant testbed using Tmote Sky sensor nodes mounted on fully autonomous MIABOT Pro miniature mobile robots. A repeatable representative selection of scaled ambulatory scenarios is presented that is quite typical of the data that will be generated in this space. The experimental results illustrate that the algorithm performs optimal power assignments, thereby ensuring a balance between energy consumption and a particular outage-based quality of service requirement while robustly compensating for disturbance uncertainties such as channel fading, interference, quantization error, noise, and nonlinear effects.","2014-12","2016-04-04 11:15:54","2016-04-05 13:33:24","","1060-1073","","4","8","","","","","","","","","","","","","","","","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/3WIPU56F/display.html","","ambient healthcare environment; ambulatory wireless sensor networks; Ambulatory wireless sensor networks (WSNs); channel fading; commercial sensor node platform; disturbance uncertainties; energy consumption; fading channels; fully autonomous MIABOT Pro miniature mobile robots; IEEE 802.15.4; IEEE 802.15.4 compliant testbed; IEEE 802.15 Standards; IEEE standards; minimax techniques; min-max model predictive control approach; min-max model predictive controller; min???max model predictive control (MPC); min–max model predictive control (MPC); min-max model predictive control (MPC); multiparametric programming; multiparametric quadratic solver; node location; node movement; node orientation; nonlinear effects; optimal power assignments; outage-based quality of service; piecewise-affine function; power control; power controller; power system management; predictive control; quality of service; quantization error; received signal strength indicator (RSSI)-based power control; repeatable representative selection; resource-constrained wireless sensor; resource-constrained wireless sensors; resource efficient algorithm; robust control; robust control law; Robustness; robust power management; scaled ambulatory scenarios; sensor data; Sensors; telecommunication channels; telecommunication control; Tmote Sky sensor nodes; tracking error; uncertain linear state-space model; Wireless communication; wireless sensor networks","Ambulatory wireless sensor networks (WSNs); IEEE 802.15.4; min-max model predictive control (MPC); multiparametric programming; piecewise-affine function; received signal strength indicator (RSSI)-based power control; resource-constrained wireless sensor","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TFP6CN3D","journalArticle","2002","Gieseg, M.A.; Cody, T.; Man, M.Z.; Madore, S.J.; Rubin, M.A.; Kaldjian, E.P.","Expression profiling of human renal carcinomas with functional taxonomic analysis","BMC Bioinformatics","","1471-2105","10.1186/1471-2105-3-26","","Background: Molecular characterization has contributed to the understanding of the inception, progression, treatment and prognosis of cancer. Nucleic acid array-based technologies extend molecular characterization of tumors to thousands of gene products. To effectively discriminate between tumor sub-types, reliable laboratory techniques and analytic methods are required. Results: We derived mRNA expression profiles from 21 human tissue samples (eight normal kidneys and 13 kidney tumors) and two pooled samples using the Affymetrix GeneChip platform. A panel of ten clustering algorithms combined with four data pre-processing methods identified a consensus cluster dendrogram in 18 of 40 analyses and of these 16 used a logarithmic transformation. Within the consensus dendrogram the expression profiles of the samples grouped according to tissue type; clear cell and chromophobe carcinomas displayed distinctly different gene expression patterns. By using a rigorous statistical selection based method we identified 355 genes that showed significant (p < 0.001) gene expression changes in clear cell renal carcinomas compared to normal kidney. These genes were classified with a tool to conceptualize expression patterns called ""Functional Taxonomy"". Each tumor type had a distinct ""signature,"" with a high number of genes in the categories of Metabolism, Signal Transduction, and Cellular and Matrix Organization and Adhesion. Conclusions: Affymetrix GeneChip profiling differentiated clear cell and chromophobe carcinomas from one another and from normal kidney cortex. Clustering methods that used logarithmic transformation of data sets produced dendrograms consistent with the sample biology. Functional taxonomy provided a practical approach to the interpretation of gene expression data. © 2002 Gieseg et al; licensee BioMed Central Ltd.","2002","2016-04-04 17:51:10","2016-04-04 17:51:10","","","","","3","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/PJ9JRZCF/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZ2C9C4J","journalArticle","1974","Miller, R.H.; Hennessey, G.","Infrared coatings for 2-15 μm","Proceedings of SPIE - The International Society for Optical Engineering","","0277-786X","10.1117/12.954109","","This paper addresses the following aspects of 2–15 μm infrared coating technology: Theoretical design and analysis, properties of film and substrate materials, spectrophotometric measurement techniques, and examples of principle coating designs. Theoretical investigations are carried out using a self-optimizing multilayer thin film design program as well as classical Herpin design techniques. Optimization examples are given to illustrate the results. It is shown how the computer can be used to predict the degree of difficulty in manufacturing some types of infrared coating designs. Examples are given showing how the performance of bandpass filter designs is influenced by the f-number of the incident light beam and absorption in the film layers. Our principle instrument for infrared measurements is the Perkin-Elmer 180 Spectrophotometer, and we outline the techniques used for low temperature measurements, specular reflectance measurements, polarization measurements, and ATR measurements of our evaporated coatings. Finally, a representative selection of coatings spanning the 2-15 μm range is presented and discussed, including narrow and broadband anti-reflection coatings, bandpass filters, short and long wave pass filters, laser reflectors, and black mirrors. © 1974, SPIE.","1974","2016-04-04 17:48:05","2016-04-04 17:48:05","","119-141","","","50","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/MDF7RBNA/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UAZIN5SW","conferencePaper","2008","Chen, G.; Wilson, C.","Use of self-organizing maps for texture feature selection in content-based image retrieval","","978-1-4244-1821-3","","10.1109/IJCNN.2008.4633882","","The ""Semantic Gap"" observed in content-based image retrieval (CBIR) has become a highly active research topic in last twenty years, and it is widely accepted that domain specification is one of the most effective methods of addressing this problem. However, along with the challenge of making a CBIR system specific to a particular domain comes the challenge of making those features object dependent. Independent Component Analysis (ICA) is a powerful tool for detecting underlying texture features in images. However, features detected in this way often contain groups of features which are essentially shifted or rotated versions of each other. Thus, a method of dimensionality reduction that takes this self-similarity into account is required. In this paper, we proposed a Self-Organizing Map (SOM) based clustering method to reduce the dimensionality of feature space. This method comprises two phases: clustering as well as representative selection. The result of the implementation confirms this method offers effective CBIR dimensionality reduction when using the ICA method of texture feature extraction. © 2008 IEEE.","2008","2016-04-04 17:48:05","2016-04-04 17:48:05","","765-770","","","","","","","","","","","","","English","","","Scopus","","Scopus","","DOI: 10.1109/IJCNN.2008.4633882","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/TMZ9AQET/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Joint Conference on Neural Networks","","","","","","","","","","","","","","",""
"UC8DMKMB","journalArticle","2005","Nemeth, K.A.; Singh, A.V.; Knudsen, T.B.","Searching for biomarkers of developmental toxicity with microarrays: Normal eye morphogenesis in rodent embryos","Toxicology and Applied Pharmacology","","0041-008X","10.1016/j.taap.2004.12.013","","Gene expression arrays reveal the potential linkage of altered gene expression with specific adverse effects leading to disease phenotypes. But how closely do microarray data reflect early physiological or pharmacological measures that predict toxic event(s)? To explore this issue, we have undertaken experiments in early mouse embryos exposed to various teratogens during neurulation stages with the aim of correlating large-scale changes in gene expression across the critical period during exposure. This study reports some of the large-scale changes in gene expression that can be detected in the optic rudiment of the developing mouse and rat embryo across the window of development during which the eye is exceedingly sensitive to teratogen-induced micro-/anophthalmia. Microarray analysis was performed on RNA from the headfold or ocular region at the optic vesicle and optic cup stages when the ocular primordium is enriched for Pax-6, a master control gene for eye morphogenesis. Statistical selection of differentially regulated genes and various clustering techniques identified groups of genes in upward or downward trajectories in the normal optic primordium during early eye development in mouse and rat species. We identified 165 genes with significant differential expression during eye development, and a smaller subset of 58 genes that showed a tight correlation between mouse-rat development. Significantly over-represented functional categories included fatty acid metabolism (up-regulated) and glycolysis (down-regulated). From studies such as these that benchmark large-scale gene expression during normal embryonic development, we may be able to identify the panel of biomarkers that best correlate with species differences and the risks for developmental toxicity. © 2005 Elsevier Inc. All rights reserved.","2005","2016-04-04 17:51:10","2016-04-04 17:51:10","","219-228","","2","206","","","Searching for biomarkers of developmental toxicity with microarrays","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/77NUHX3R/display.html","","","Developmental toxicity; Microarray; Normal eye","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V9AQQSZA","journalArticle","2006","Yang, Y.; Webb, G.; Cerquides, J.; Korb, K.; Boughton, J.; Ting, K.M.","To select or to weigh: A comparative study of model selection and model weighing for SPODE ensembles","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","0302-9743","","","An ensemble of Super-Parent-One-Dependence Estimators (SPODEs) offers a powerful yet simple alternative to naive Bayes classifiers, achieving significantly higher classification accuracy at a moderate cost in classification efficiency. Currently there exist two families of methodologies that ensemble candidate SPODEs for classification. One is to select only helpful SPODEs and uniformly average their probability estimates, a type of model selection. Another is to assign a weight to each SPODE and linearly combine their probability estimates, a methodology named model weighing. This paper presents a theoretical and empirical study comparing model selection and model weighing for ensembling SPODEs. The focus is on maximizing the ensemble's classification accuracy while minimizing its computational time. A number of representative selection and weighing schemes are studied, providing a comprehensive research on this topic and identifying effective schemes that provide alternative trades-off between speed and expected error. © Springer-Verlag Berlin Heidelberg 2006.","2006","2016-04-04 17:48:05","2016-04-04 17:48:05","","533-544","","","4212 LNAI","","","To select or to weigh","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/G6DECADI/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VGDC6D2M","journalArticle","2014","Wang, L.; Wu, S.; Li, H.","Seed representatives selection for supervised clustering","ICIC Express Letters, Part B: Applications","","2185-2766","","","Supervised clustering aims to find a valuable subset of a labeled data set by optimizing a given objective function. Although a number of supervised clustering algorithms try to obtain the subset by stochastic searching, the result subsets are indefinite. In this paper an existing supervised clustering algorithm named SRIDHCR was analyzed. By filling a seed representative set with boundary samples, SBPS, a selection algorithm for seed representatives is proposed to initialize SRIDHCR. The experimental results on UCI datasets demonstrate our algorithm is able to find the definite solutions which are the same as or even better than those in literature. © 2014 ICIC International.","2014","2016-04-04 17:48:05","2016-04-04 17:48:05","","645-649","","3","5","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/APIFQNWJ/display.html","","","Seed representatives; Subset selection; Supervised clustering; Topology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VNF85RG8","journalArticle","2012","Schöllnberger, H.; Kaiser, J.C.; Jacob, P.; Walsh, L.","Dose-responses from multi-model inference for the non-cancer disease mortality of atomic bomb survivors","Radiation and Environmental Biophysics","","0301-634X","10.1007/s00411-012-0410-4","","The non-cancer mortality data for cerebrovascular disease (CVD) and cardiovascular diseases from Report 13 on the atomic bomb survivors published by the Radiation Effects Research Foundation were analysed to investigate the dose-response for the influence of radiation on these detrimental health effects. Various parametric and categorical models (such as linear-no-threshold (LNT) and a number of threshold and step models) were analysed with a statistical selection protocol that rated the model description of the data. Instead of applying the usual approach of identifying one preferred model for each data set, a set of plausible models was applied, and a sub-set of non-nested models was identified that all fitted the data about equally well. Subsequently, this sub-set of non-nested models was used to perform multi-model inference (MMI), an innovative method of mathematically combining different models to allow risk estimates to be based on several plausible dose-response models rather than just relying on a single model of choice. This procedure thereby produces more reliable risk estimates based on a more comprehensive appraisal of model uncertainties. For CVD, MMI yielded a weak dose-response (with a risk estimate of about one-third of the LNT model) below a step at 0.6 Gy and a stronger dose-response at higher doses. The calculated risk estimates are consistent with zero risk below this threshold-dose. For mortalities related to cardiovascular diseases, an LNT-type dose-response was found with risk estimates consistent with zero risk below 2.2 Gy based on 90% confidence intervals. The MMI approach described here resolves a dilemma in practical radiation protection when one is forced to select between models with profoundly different dose-responses for risk estimates. © The Author(s) 2012.","2012","2016-04-04 17:51:10","2016-04-04 17:51:10","","165-178","","2","51","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/DXK422R6/display.html","","","Cardiovascular diseases; Cerebrovascular disease; LNT; Radiation; Risk assessment; Threshold-dose","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W45MEH9N","conferencePaper","2013","Legato, P.; Mazza, R.M.","Addressing robust berth planning under uncertainty via simulation based optimization","","","","","","Decisions of allocating berth segments to incoming vessels, in maritime container terminals, has been extensively modeled in the scientific literature by resorting to formulations of mathematical programming with integer variables. Both vessel arrival times and processing times are usually considered as a deterministic input to the mathematical model despite of the uncertainty affecting berth decisions at the operational level, when several unpredictable events and operation delays occur and require to be managed. In this paper, we propose to apply the methodology of simulation based optimization to cope with uncertainty: a constructive algorithm is used to obtain a weekly plan at the tactical level; the allocation decisions are then adjusted at the operational level. Randomness in events and operations is taken into account by Monte Carlo simulation, while moving-average sample mean estimators are used to reduce the number of simulation runs required. Preliminary numerical results are also given.","2013","2016-04-04 17:51:10","2016-04-04 17:51:10","","144-152","","","","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/3N8WGRTB/display.html","","","Berth planning; Port logistics; Simulation optimization; statistical selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","12th International Conference on Modeling and Applied Simulation, MAS 2013, Held at the International Multidisciplinary Modeling and Simulation Multiconference, I3M 2013","","","","","","","","","","","","","","",""
"WPGF9834","journalArticle","2005","Sundt, T.M.","Technology insight: Randomized trials of off-pump versus on-pump coronary artery bypass surgery","Nature Clinical Practice Cardiovascular Medicine","","1743-4297","10.1038/ncpcardio0190","","Coronary artery bypass grafting has proven a remarkably effective treatment for occlusive coronary artery disease, with demonstrable impact on both symptoms and survival. As conducted traditionally, cardiopulmonary bypass is required, and a global myocardial ischemic insult imposed with aortic occlusion under the protection of cardioplegic arrest. Despite the remarkable success of this approach, concerns over the systemic effects of bypass, including neurologic sequelae as wen as ischemic myocardial injury, have stimulated development of techniques and technology to perform coronary bypass'off-pump'. This technique obviates the need for the bypass machine and imposes only brief regional ischemia during construction of each individual anastomosis. Despite enthusiastic support by a devoted cohort of surgeons, and a host of nonrandomized retrospective studies demonstrating an apparent benefit to the off-pump technique, the technique has not been universally adopted. How can there be such controversy over what appears to be a superior approach? In part, many surgeons are concerned that the greater technical difficulty of the technique will impact long-term results adversely. There is also uncertainty with regard to the actual advantage of off-pump coronary artery bypass over the tried-and-true methods. Surgeons recognize that the results of any surgical series are particularly subject to the influence of subtle selection biases. Accordingly, prospective randomized studies add particular value to the debate. It is the aim of this review to examine the evidence for off-pump coronary artery bypass critically, from a surgeon's perspective, with particular emphasis on knowledge derived from a representative selection of published prospective randomized studies.","2005","2016-04-04 17:48:05","2016-04-04 17:48:05","","261-268","","5","2","","","Technology insight","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/29I2KQQ8/display.html","","","Coronary artery bypass grafting; Coronary artery disease; Neurologic dysfunction; Off-pump coronary artery bypass; Randomized trial","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X6VCX9D5","journalArticle","2014","Romeijnders, W.; Stougie, L.; van, der Vlerk","Approximation in two-stage stochastic integer programming","Surveys in Operations Research and Management Science","","1876-7354","10.1016/j.sorms.2014.04.001","","Approximation algorithms are the prevalent solution methods in the field of stochastic programming. Problems in this field are very hard to solve. Indeed, most of the research in this field has concentrated on designing solution methods that approximate the optimal solution value. However, efficiency in the complexity theoretical sense is usually not taken into account. Quality statements mostly remain restricted to convergence to an optimal solution without accompanying implications on the running time of the algorithms for attaining more and more accurate solutions.However, over the last thirty years also some studies on performance analysis of approximation algorithms for stochastic programming have appeared. In this direction we find both probabilistic analysis and worst-case analysis.Recently the complexity of stochastic programming problems has been addressed, indeed confirming that these problems are harder than most deterministic combinatorial optimization problems. Polynomial-time approximation algorithms and their performance guarantees for stochastic linear and integer programming problems have received increasing research attention only very recently.Approximation in the traditional stochastic programming sense will not be discussed in this chapter. The reader interested in this issue is referred to surveys on stochastic programming, like the Handbook on Stochastic Programming by Ruszczyński and Shapiro (2003) or the textbooks by Birge and Louveaux (1997), Kall and Wallace (1994), Prékopa (1995), and Shapiro etal. (2009). We concentrate on the studies of approximation algorithms in relation to computational complexity theory.With this survey we intend to give a flavor of the type of results existing in the literature on approximation algorithms in two-stage stochastic integer programming rather than a complete overview of the literature on the subject. We do so by exhibiting a representative selection of results, which we present in full detail. While presenting them we do not refer to the literature; these references, together with pointers to other relevant work in this field of research, are given in an extensive notes section at the end of the survey. © 2014 Elsevier Ltd.","2014","2016-04-04 17:48:05","2016-04-04 17:48:05","","17-33","","1","19","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/UQST8N3H/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z4NNM2PG","conferencePaper","2015","Dang, C.; Al-Qizwini, M.; Radha, H.","Representative selection for big data via sparse graph and geodesic Grassmann manifold distance","","978-1-4799-8297-4","","10.1109/ACSSC.2014.7094591","","This paper addresses the problem of identifying a very small subset of data points that belong to a significantly larger massive dataset (i.e., Big Data). The small number of selected data points must adequately represent and faithfully characterize the massive Big Data. Such identification process is known as representative selection [19]. We propose a novel representative selection framework by generating an ℓ<inf>1</inf> norm sparse graph for a given Big-Data dataset The Big Data is partitioned recursively into clusters using a spectral clustering algorithm on the generated sparse graph. We consider each cluster as one point in a Grassmann manifold, and measure the geodesic distance among these points. The distances are further analyzed using a min-max algorithm [1] to extract an optimal subset of clusters. Finally, by considering a sparse subgraph of each selected cluster, we detect a representative using principal component centrality [11]. We refer to the proposed representative selection framework as a Sparse Graph and Grassmann Manifold (SGGM) based approach. To validate the proposed SGGM framework, we apply it onto the problem of video summarization where only few video frames, known as key frames, are selected among a much longer video sequence. A comparison of the results obtained by the proposed algorithm with the ground truth, which is agreed by multiple human judges, and with some state-of-the-art methods clearly indicates the viability of the SGGM framework. © 2014 IEEE.","2015","2016-04-04 17:48:05","2016-04-04 17:48:05","","938-942","","","2015-April","","","","","","","","","","English","","","Scopus","","Scopus","","DOI: 10.1109/ACSSC.2014.7094591","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/XREIPPJ9/display.html","","","geodesic Grassmann manifold distance; principal component centrality; sparse graph","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Conference Record - Asilomar Conference on Signals, Systems and Computers","","","","","","","","","","","","","","",""
"ZAE9THWW","journalArticle","2012","Starrfelt, J.; Kokko, H.","Bet-hedging-a triple trade-off between means, variances and correlations","Biological Reviews","","1464-7931","10.1111/j.1469-185X.2012.00225.x","","In unpredictably varying environments, strategies that have a reduced variance in fitness can invade a population consisting of individuals that on average do better. Such strategies 'hedge their evolutionary bets' against the variability of the environment. The idea of bet-hedging arises from the fact that appropriate measure of long-term fitness is sensitive to variance, leading to the potential for strategies with a reduced mean fitness to invade and increase in frequency. Our aim is to review the conceptual foundation of bet-hedging as a mechanism that influences short- and long-term evolutionary processes. We do so by presenting a general model showing how evolutionary changes are affected by variance in fitness and how genotypic variance in fitness can be separated into variance in fitness at the level of the individuals and correlations in fitness among them. By breaking down genotypic fitness variance in this way the traditional divisions between conservative and diversified strategies are more easily intuited, and it is also shown that this division can be considered a false dichotomy, and is better viewed as two extreme points on a continuum. The model also sheds light on the ideas of within- and between-generation bet-hedging, which can also be generalized to be seen as two ends of a different continuum. We use a simple example to illustrate the virtues of our general model, as well as discuss the implications for systems where bet-hedging has been invoked as an explanation. © 2012 The Authors. Biological Reviews © 2012 Cambridge Philosophical Society.","2012","2016-04-04 17:51:10","2016-04-04 17:51:10","","742-755","","3","87","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/FJ9UUCVN/display.html","","","Bet-hedging; Diversification; Environmental variability; Fitness; Uncertainty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZBN3UWF5","journalArticle","2010","Vignes, B.; Aadnøy, B.S.","Well-integrity issues offshore Norway","SPE Production and Operations","","1930-1855","","","A number of serious well failures in recent years led to investigations of well-integrity issues. The Petroleum Safety Authority Norway (PSA) performed a pilot well-integrity survey based on supervisory audits and requested input from seven operating companies, 12 preselected offshore facilities, and 406 wells. The wells were a representative selection of production and injection wells with variation in both age and development categories. The pilot project indicates that 18% of the wells in the survey have integrity failure, issues, or uncertainties, and 7% of these are shut in because of well-integrity issues. The selection of wells and the companies indicate that the statistics are representative. The well incidents in the past and the results of the pilot well-integrity survey revealed that the industry needs to increase focus on barrier philosophy. Control of barrier status is an important health, safety, and environment (HSE) factor to avoid major incidents caused by unintentional leaks and well-control situations. Knowledge of well-integrity status at all times enables the companies to take the right actions in a proactive manner to prevent incidents. The paper presents the results and the conclusions from the pilot survey. In addition, a number of technical well failures will be presented, identifying critical elements such as corrosion, leaks, and operational factors. In particular, the understanding of barrier regulations, standards, and implementation was found to be inadequate. Copyright © 2010 Society of Petroleum Engineers.","2010","2016-04-04 17:48:05","2016-04-04 17:48:05","","145-150","","2","25","","","","","","","","","","English","","","Scopus","","Scopus","","","","/home/gschardong/.zotero/zotero/nah1hk19.default/zotero/storage/FTIUW2WQ/display.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""